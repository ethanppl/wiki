# Artificial Intelligence

Anything about computers learning and "thinking".

Learning AI provides us a way to learn about ourselves, how does human
consciousness and intelligence work?

## Resources

- [Fast AI Course](https://course.fast.ai/)
  - Full free online course on deep learning
  - [Fastbook](https://github.com/fastai/fastbook),
    [YouTube Playlist](https://www.youtube.com/playlist?list=PLfYUBJiXbdtSvpQjSnJJ_PmDQB_VyT5iU)
- [Neutral Networks and Deep Learning | Michael Nielson](http://neuralnetworksanddeeplearning.com/)
  - Learning neural networks by building one to recognize handwritten digits

Courses

- [Neural Networks: Zero to Hero](https://www.youtube.com/watch?v=VMj-3S1tku0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&ab_channel=AndrejKarpathy)
  ([Website](https://karpathy.ai/zero-to-hero.html))
- [Stanford CS229: Machine Learning by Andrew Ng](https://www.youtube.com/watch?v=jGwO_UgTS7I&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=1&ab_channel=StanfordOnline)
  (Autumn 2019)
- [Standford CS221: Artificial Intelligence: Principles and Techniques](https://www.youtube.com/watch?v=J8Eh7RqggsU&list=PLoROMvodv4rO1NB9TD4iUZ3qghGEGtqNX&ab_channel=StanfordOnline)
  (Autumn 2019)
- [Standford CS231n: Deep Learning for Computer Vision](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&ab_channel=StanfordUniversitySchoolofEngineering)
  (Spring 2017) ([Course Website](http://cs231n.stanford.edu/))
- [MIT 6.034: Artificial Intelligence by Patrick Henry Winston](https://www.youtube.com/watch?v=TjZBTDzGeGg&list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi&ab_channel=MITOpenCourseWare)
  (Fall 2010)
- [MIT 6.S191: Introduction to Deep Learning](https://www.youtube.com/watch?v=QDX-1M5Nj7s&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&index=1&ab_channel=AlexanderAmini)
  (Spring 2018 - Spring 2023)
- [MIT 6.S099: Artificial General Intelligence](https://www.youtube.com/watch?v=-GV_A9Js2nM&list=PL4jieTF-BpWoiVjta6VuRy5plFtDm9eRG&ab_channel=LexFridman)
  (Spring 2018)
- [Deep Learning Foundations to Stable Diffusion | Fast.AI](https://www.youtube.com/watch?v=_7rMfsA24Ls&list=PLfYUBJiXbdtRUvTUYpLdfHHp9a58nWVXP&ab_channel=JeremyHoward)
  ([Website](https://course.fast.ai/Lessons/part2.html))
- [Machine Learning Video Library | Caltech](https://work.caltech.edu/library/)
  â€” Videos categorized by topics in machine learning

## Links

- [The Waluigi Effect Meta Post](https://www.lesswrong.com/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post)
  ([HN](https://news.ycombinator.com/item?id=35042431))
  - An interesting hypothesis is that some prompt has adverse effects on the
    model
  - "After you train an LLM to satisfy a desired property _P_, then it is easier
    to elicit the LLM into satisfying the opposite of _P_"
  - Could like to see more evidence and examples though
- [What are transformer models](https://txt.cohere.ai/what-are-transformer-models/)
  ([HN](https://news.ycombinator.com/item?id=35576918))
  - If you want a higher-level explanation with examples of the process of
    tokenization, embedding, positional encoding, the transformer block,
    attention and the softmax layer
  - If you have the patience, try reading the
    [original paper](https://arxiv.org/abs/1706.03762). The top comment in the
    HN post summarized a few oversimplifications or mistakes in the article.
- [A Cookbook of Self-Supervised Learning](https://arxiv.org/abs/2304.12210)
  ([PDF](https://arxiv.org/pdf/2304.12210.pdf))
  ([HN](https://news.ycombinator.com/item?id=35702490))
  - 70 pages cookbook lowering the barrier of entry for training AI with
    self-supervised learning
- [Self-healing Code is the Future of Software Development | StackOverflow](https://stackoverflow.blog/2023/06/07/self-healing-code-is-the-future-of-software-development/)
  - Give a goal to the AI, the AI uses its output to prompt itself again
  - E.g.: feed the AI code, compilation error or execution logs back to the AI
    and ask the AI to improve
  - [These loops are prone to distractions though.](https://twitter.com/emollick/status/1645609531240587265)
    "Technology marches on, but procrastination remains unbeaten." lol
- [How to make a QR code with Stable Diffusion | Stable Diffusion Art](https://stable-diffusion-art.com/qr-code/)
  - This works for me, things like city, buildings and castle works well
  - It uses the image-to-image with `ControlNet` to "paint" the QR code
  - The link to the
    [`GhostMix` model](https://civitai.com/api/download/models/76907) it uses
  - The later the `ControlNet` starts or the earlier it ends the photo is more
    realistic, but risking of losing the QR code
- [Embeddings: what are they and why they matter | Simon Willison](https://simonwillison.net/2023/Oct/23/embeddings/)
  - Embeddings: turn any piece of data into a fixed-length vector
  - Finding related contents and relationship between words, e.g. `germany` +
    (`paris` - `france`) = `berlin` in Word2Vec
  - CLIP: multimodal embeddings for both images and text provide interesting
    image searching capabilities
  - Retrieval-augmented generation (RAG): generate embeddings for a collection
    of documents, use embeddings to find similar documents with the question,
    paste original excerpts of the documents alongside the question to the LLM
    to generate answers
- [Machine Learning Engineering Open Book](https://github.com/stas00/ml-engineering)
  - Collections of concepts, methodologies, tools and tips to train LLM and VLM
- [Ask HN: What have you built with LLMs?](https://news.ycombinator.com/item?id=39263664)
  - [ChatGPT Phone](https://github.com/kevingduck/ChatGPT-phone/) to practice
    cold calls
- [Building the next generation of AI infrastructure at home | IFP](https://ifp.org/compute-in-america-building-the-next-generation-of-ai-infrastructure-at-home/)
  - [How to Build an AI Data Center](https://ifp.org/compute-in-america-building-the-next-generation-of-ai-infrastructure-at-home/)
    - Cost, power, computing devices, network, cooling, reliability
- [Summary of Ilya Sutskevers AI Reading List](https://tensorlabbet.com/2024/09/24/ai-reading-list/)
  - A list of short summaries of the 30 papers reading list
- [The society of mind | Marvin Minsky](http://aurellem.org/society-of-mind/)
  - A book proposing a model where intelligence is like a society of agents
  - A way to model artificial intelligence, and maybe a way to model how human
    mind works
- [Why the deep learning boom caught almost everyone by surprise](https://www.understandingai.org/p/why-the-deep-learning-boom-caught)
  - The story of three stubborn non-conformist
    - Geoffrey Hinton promoting neural networks
    - Jensen Huang recognizing GPUs can be used to train AI and developing CUDA
    - Fei-Fei Li creating ImageNet
  - And the story of how the three converges to form modern AI
