"use strict";(self.webpackChunkmy_wiki=self.webpackChunkmy_wiki||[]).push([[8130],{7735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/2025/05/25/self-host","metadata":{"permalink":"/blog/2025/05/25/self-host","source":"@site/blog/2025-05-25-self-host.md","title":"My $4/month self-hosted web server setup","description":"This blog documented my setup for self-hosting a web server. Hopefully this is","date":"2025-05-25T00:00:00.000Z","tags":[{"inline":true,"label":"Computers","permalink":"/blog/tags/computers"},{"inline":true,"label":"Self Hosting","permalink":"/blog/tags/self-host"}],"readingTime":38.78,"hasTruncateMarker":true,"authors":[{"name":"Ethan Pang","url":"https://ethanppl.com/","imageURL":"https://github.com/ethanppl.png","key":"ethan","page":null}],"frontMatter":{"title":"My $4/month self-hosted web server setup","tags":[{"label":"Computers","permalink":"computers"},{"label":"Self Hosting","permalink":"self-host"}],"toc_min_heading_level":2,"toc_max_heading_level":2,"authors":"ethan"},"unlisted":false,"nextItem":{"title":"Reimplement all JavaScript Array Functions with while loops only","permalink":"/blog/2025/02/23/js-array"}},"content":"This blog documented my setup for self-hosting a web server. Hopefully this is\\nhelpful for others to get started with hosting your web server. I was intimated\\nby all the potential cost and complexity before, but after all, it was not that\\ncomplicated.\\n\\nIt starts from renting a virtual machine and setting the machine up, to running\\nmy web servers in containers, setting DNS records, running Nginx and monitoring\\ntools. All cost me on average less than $4 a month. Including the cost of\\nrenting my own domain, it is still less than $5 per month on average.\\n\\nIt gave me a lot of fun to tinker with things. It allows me to host more than 1\\nweb server on the same machine using nginx. I would like to share the steps,\\nthought process and learnings in details.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Overview\\n\\nLast year, I created [my playground](https://playground.ethanppl.com/). It is a\\nweb server that power real time, turn-based multiplayer game. The major\\ndifference it has with all the tools I built before was it needs a server.\\nUnlike this Wiki, the content and service it provides are not static. It cannot\\nbe hosted as a static site on GitHub Pages for free. To synchronize and power\\nreal time multiplayer, I need a server on the Internet that is always up that\\nclients can connect to.\\n\\n### Why I chose self-hosting\\n\\nThere are multiple ways to do this. With\\n[platform as a service](https://en.wikipedia.org/wiki/Platform_as_a_service) or\\nsimilar cloud services model, I could just use the right platform to host. It\\nshould be easier to set up and configure, with less overhead and initial cost.\\nHowever, because it is just a hobby project, the stakes are low. I think it is\\nworth to figure out how to self-host.\\n\\nSelf-hosting allows me to tinker with networking, containers, server management,\\nand more. By having a machine running, it also opens the possibility to host\\nmore than 1 web services on it. I started with hosting\\n[the playground server](https://playground.ethanppl.com/), soon added my own\\n[plausible analytics server](https://plausible.io/), an error tracking server\\ncalled [glitchtip](https://glitchtip.com/), and more. All running on this small\\nmachine in the data center. There is no additional cost for each new server I\\nadd to the server.\\n\\nThe server with just 2 vCPUs and 4 GB of RAM, with 20 TB traffic included, is\\nable to power a lot of services. The server itself cost less than $4 a month.\\nConsidering, Plausible cloud service cost $9 a month, and most cloud providers\'\\nweb services with much tinier machine still cost a few dollars a month.\\nSelf-hosting is a great deal.\\n\\nThis guide includes my notes and thought process while researching and setting\\nup things. It started from purchasing my own domain. Then, researching and\\ndeciding to rent a virtual machine from Hetzner, configure it and setting it up.\\nRunning my web server in a container in the VM. All the configurations required\\nto route traffic to the web server and finally monitoring tools for the server.\\n\\n### Architecture Overview\\n\\nBefore I go over the setup step by step, it would be great to go over the major\\ncomponents in the setup and some terminologies so that we are aligned.\\n\\n![architecture](./assets/self-host/architecture.png)\\n\\nWhen user request for `playground.ethanppl.com`, what happens is your computer\\nneed to know where that is hosted. It sends a domain name system (DNS) query to\\nDNS servers to ask for the IP address for the `playground.ethanppl.com` domain.\\nOnce it gets the IP address, it sends a request to this IP address at port 80 to\\nget the web page. This guide will go through how to configure and set up your\\ndomain and DNS. For more about how the Internet work I suggest checking out\\n[The Internet, Explained from First Principle](https://explained-from-first-principles.com/internet/)\\nor other resources in the [Computer Network Page](/computers/network/network) in\\nthis Wiki.\\n\\nFrom here, the definition of the \\"server\\" can get a bit confusing. There are\\nmultiple web servers supporting multiple services that can be run on the same\\nserver machine. It is like your computer can run different apps, process,\\nservers on the same machine. We can run multiple web servers on the same\\nmachine.\\n\\nRequests coming from the Internet reach our IP address. The computer listening\\nto these requests is the _server_. I hosted this server on\\n[Hetzner](https://www.hetzner.com/cloud/), a cloud provider providing cheap\\nvirtual machines and the IP addresses. This virtual private server (VPS) is like\\na normal computer that is accessible from the Internet. In this guide, I will\\nrefer to this server as the virtual machine (VM), the server machine, or just\\nthe Hetzner VPS. I will explain why I chose Hetzner and how to set it up below.\\n\\nWithin the server machine, all incoming requests go through\\n_[nginx](https://nginx.org/en/)_, a reverse proxy running natively on the\\nvirtual machine. A\\n[reverse proxy](https://www.cloudflare.com/en-gb/learning/cdn/glossary/reverse-proxy/)\\nis like a server sitting in front of our real server, relaying messages between\\nthe clients and the server. Nginx looks at what servers you are requesting, in\\nthis case `playground.ethanppl.com`, and route this to the corresponding service\\nthat are handling these requests. Say another request is going to\\n`plausible.ethanppl.com`, nginx will route this to a separate service. Nginx is\\nthe magic that allow us to run multiple web services on the same server machine.\\nIt is also responsible for supporting HTTP2, HTTP3 and HTTPS. All explained\\nbelow.\\n\\nAll the web services on the server are running in\\n_[containers](https://www.docker.com/resources/what-container/)_. It provides an\\nisolated way to run these services without them intervening each other. The\\ncontainers are the actual \\"web servers\\" that are providing the service. I will\\nalso explain how I ran the database that the playground web server use in a\\ncontainer, and how to set up docker volumes and network for this local database.\\n\\nIt is OK if all the terminologies sounds a lot. I will explain in details below.\\nAll you need to be aware of right now is the difference between the server\\nmachine and the web servers. I will first talk about the server machine hosted\\non Hetzner, then how to run containers in the server machine, and lastly\\nconfigure Nginx and wiring things up.\\n\\n:::note\\n\\nTerminologies:\\n\\n- **DNS**: translates domain name to IP address\\n- **Server machine**:\\n  - A web server rent from Hetzner running in a data center in Finland\\n  - Also referenced as the Hetzner VPS, or the virtual machine\\n- **nginx**:\\n  - A reverse proxy server in front of the real web server\\n  - Handle piping the traffic to the right server based on the domain requesting\\n  - Handle HTTPS, HTTP2 and HTTP3\\n- **Containers**: the actual web servers\\n\\n:::\\n\\nThis blog turns out to be longer than I initially thought. However, I do not\\nwant this to be intimidating for people who want to try self-hosting. Instead, I\\nwould like to write down all my thought process and things I learned along the\\nway to help anyone hesitate to start.\\n\\nThis document is structured as if you were following along self-hosting your own\\nPlayground server. There are notes for some key steps and concepts. I wish this\\ndocument is something I could read beforehand, telling me self-hosting is not\\nthat hard and not that expensive!\\n\\nIf you are ready, let\'s start from the first thing I did, getting a domain name.\\n\\n## Register a Domain\\n\\nWhen I decided to self-host my server, the first thing I did is to purchase my\\nown `ethanppl.com` domain. If you have a domain, you can skip forward to\\n[renting a Hetzner VPS](#renting-a-hetzner-vps).\\n\\nRegistering a domain technically is not related to self-hosting. It is not\\nrequired to run a server. It is possible to directly connect to the server over\\nthe Internet with IP address and port number. However, having a hostname is\\neasier to visit, share, or get a certificate for HTTPS.\\n\\nThere are many domain registrars. I got mine from\\n[Cloudflare](https://www.cloudflare.com/en-gb/products/registrar/). It is cheap\\nand easy to set up. I got my domain for 2 years with less than 20 USD.\\nCloudflare provides free whois protection, DNSSEC, email routing, etc. by\\ndefault. I have heard that [Namecheap](https://www.namecheap.com/) and\\n[Porkbun](https://porkbun.com/) both works well with the developer community.\\nYou can read\\n[this article from the Pragmatic Engineer](https://blog.pragmaticengineer.com/domain-registrars-which-developers-recommend/)\\nfor more.\\n\\n## Renting a Hetzner VPS\\n\\nTo self-host, you need a server. The server is just a computer that runs 24\\nhours and connected to the Internet.\\n\\n### Where to host\\n\\nYou could use a machine you have or use a cloud provider. The difference is\\nwhether you manage the physical metal machine, networking, electricity and\\noperating system, or pay a cloud provider to handle that. I considered hosting\\nwith a machine at home, but I chose to rent a VM from a cloud provider in the\\nend.\\n\\nI have an old laptop sitting next to me unused, or I could buy a\\n[Raspberry Pi](https://www.raspberrypi.org/). The benefit is there will be no\\nongoing cloud subscription fee to rent a VM. For a cheaper price, I get better\\nperformance. It allows me to learn more, figure out more details and\\nunderstanding more on bare metal operating systems and servers. The latency for\\nme to connect to the service I host is also extremely low as it sits next to me.\\n\\nOne of the bigger hurdles to use a machine at home is to ensure a stable IP\\naddress for this machine to be reachable over the Internet. But for most home\\naddress, the IP address might be dynamic, or go through\\n[network address translation](https://en.wikipedia.org/wiki/Network_address_translation)\\nwhich makes it impossible to have a stable IP address. One possible solution is\\n[ddclient](https://github.com/ddclient/ddclient), which periodically update the\\nDNS record for you with the dynamically changing IP address. It works with all\\nmajor DNS and domain registrars including Cloudflare, Namecheap and Porkbun.\\n\\nAlso, there are greater risk in terms of privacy and security concerns. If I\\nmessed up, I am not exposing a VM in a datacenter but a computer in my home\\nnetwork. It is also going to consume electricity and network bandwidth of my\\nhome network. In the end, considering the risk and effort required, I decided to\\nrent a cloud VM.\\n\\nOut of all the options I can find online, the cheapest is renting a\\n[Hetzner VM](https://www.hetzner.com/cloud/). I chose the cheapest model I can\\nfind, CX22 machine in Helsinki, Finland. It provides 2 vCPUs, 4 GB of RAM, 40 GB\\nof storage and 20 TB of bandwidth per month. The server and a IPv4 address\\ncombined cost \u20ac3.79 each month. It is cheaper compare to all other providers\\nwith the same specs, and it is more than what I need. With this, there are a lot\\nI can do with it.\\n\\nThe biggest drawback for me is it is hosted in Finland, the roundtrip from Hong\\nKong to Finland takes time. I searched online on the typical latency and also\\ntested it after rending, it is around 0.1 to 0.3 seconds. It is definitely\\nnoticeable, but not deal-breaking for me considering the price. Hetzner started\\nto offer servers in Singapore, but with 2 to 3 times the price. I chose Finland\\ninstead.\\n\\n:::tip\\n\\nIf you would like to try Hetzner, here is my\\n[referral link for hetzner](https://hetzner.cloud/?ref=YMRI7xo3b2af). You get\\n$20 credits for free on sign up, while I get $10 after you spent $10. If you\\nhave the same setup as me, this should get yours running 5 months for free.\\n\\n:::\\n\\n:::note\\n\\nRenting on Hetzner instead of local machine because:\\n\\n- Still very cheap\\n- No need to handle problems with dynamic IP address\\n- Lower privacy and security risk\\n- Hardware maintenance is taken care by Hetzner\\n- Electricity and network cost is also handled by Hetzner\\n\\n:::\\n\\n### Hetzner Server Setup\\n\\nIf you decided to host on another cloud machine, similar set of settings should\\napply. Make sure you can connect to it over SSH, and it is accessible over the\\nInternet. After that, you may skip forward to\\n[SSH configuration tips](#ssh-connection) and\\n[running the web server in Docker](#running-the-web-server).\\n\\nTo rent a Hetzner VPS, create an account in\\n[Hetzner Cloud](https://hetzner.cloud/?ref=YMRI7xo3b2af). There might be a few\\nverifications steps involved to prevent abuse. Once the account is active, you\\ncan rent a server.\\n[Hetzner has a comprehensive guide on how to create a server](https://docs.hetzner.com/cloud/servers/getting-started/creating-a-server).\\n\\nI tried to keep my server specs closer to what I have on my laptop. I tried an\\nArm chip at first, but there were minor inconveniences I faced because of\\nslightly different versions, API or support on various stuff. It is frustrating\\nbecause I know the issue, but I cannot reproduce and test the fix locally. In\\nthe end, I went back to Amd x86 chip, same as my laptop used for development.\\n\\nMy configuration are:\\n\\n- Location: Helsinki\\n  - After considering latency and pricing, this works for me\\n- Image: Ubuntu\\n  - Just because [I use Ubuntu locally](./2024-02-29-dual-boot-guide.md) as well\\n- Typed: Shared CPU x86 (Intel/AMD)\\n  - I am not doing intensive or sensitive stuff, shared CPU is fine\\n  - I chose x86 because I am running on an x86 laptop as well\\n- Networking: IPv4 and IPv6\\n  - IPv4: My network is only IPv4, saves me a lot of hassle by having a IPv4\\n  - IPv6: It is free of charge so why not\\n- SSH keys: Create a pair and save the keys locally, use later to SSH into the\\n  machine\\n- Volumes: No, I did not create one.\\n- Firewall: No, I did not create one.\\n- Backups: No, I did not enable it.\\n- Placement groups: No, irrelevant as I only have 1 server\\n- Labels: Whatever you like, I did not add any as I only have 1 server\\n- Cloud config: See below\\n\\nCloud configuration is a set initialization configuration for newly created\\nservers.\\n[Hetzner Community has a guide for it](https://community.hetzner.com/tutorials/basic-cloud-config)\\nand I used a very similar config.\\n\\nThe few important things it set up are:\\n\\n- `fail2ban`: To prevent brute force attacks on the SSH authentication\\n- `ufw`: firewall to only allow required ports\\n- Harden SSH configs like deactivating password authentication\\n\\nI suggest read the Hetzner guide and the manual for these programs. It is worth\\nto understand the suggested security practice. Tweak it according to what you\\nwould like. Remember to change the user\'s name to your name.\\n\\n### SSH Connection\\n\\nTo connect to the server, you need to\\n[SSH](https://en.wikipedia.org/wiki/Secure_Shell) into the machine. SSH provides\\na way to connect your computer to the server computer with the terminal. It is\\nlike directly accessing the terminal of the server over the Internet, securely.\\n[Hetzner documentation has a guide as well](https://docs.hetzner.com/cloud/servers/getting-started/connecting-to-the-server).\\n\\nTo connect to a server, you run an ssh command:\\n\\n```sh\\nssh -i /path/to/private_key username@<ip_address>\\n```\\n\\n- The `-i` option for the identity file, provide the ssh private key file\\n- The username is the name set in the cloud init configuration above\\n- The IP address is the address you rent, shown on the Hetzner dashboard\\n\\nIf your cloud init config changed the port to `2222`, then\\n\\n```sh\\nssh -i /path/to/private_key -p 2222 username@<ip_address>\\n```\\n\\nFor the first time, you will most likely be prompted if you want to connect to\\nthe host. By default, confirming will save this host to `~/.ssh/known_hosts`,\\nand you will not see this warning again. Once successfully ran the command, you\\nshould see output like this:\\n\\n```\\nWelcome to Ubuntu 24.04 LTS (GNU/Linux 6.8.0-40-generic x86_64)\\n\\n * Documentation:  https://help.ubuntu.com\\n * Management:     https://landscape.canonical.com\\n * Support:        https://ubuntu.com/pro\\n\\n System information as of Sat Apr 19 03:35:28 PM UTC 2025\\n\\n  System load:  0.37               Processes:             223\\n  Usage of /:   58.7% of 37.23GB   Users logged in:       0\\n  Memory usage: 55%                IPv4 address for eth0: 100.100.100.100\\n  Swap usage:   0%                 IPv6 address for eth0: aaaa:bbbb:cccc:dddd::1\\n```\\n\\nRunning the command `exit` or pressing `Ctrl + D` will close the connection.\\n\\nThere is one additional step I did to improve the workflow. Instead of typing\\nout the command and IP address out every time, you can set up an SSH config in\\n`~/.ssh/config`. Here is my config for my server:\\n\\n```\\nHost playground\\n  HostName 100.100.100.100\\n  User ethan\\n  IdentityFile ~/.ssh/hetzner_personal\\n```\\n\\n- The host `playground` can be any name you choose.\\n- Hostname is the IP address of your server machine\\n- User is the login username\\n- Identity file is the file to the private key\\n\\nWith this configuration saved, connecting to the server is simply running\\n`ssh playground`.\\n\\n:::note\\n\\nSet up server\\n\\n- Choose suitable architecture and OS\\n- Basic firewall and SSH configurations for security measures\\n- Create an SSH config in `~/.ssh/config` locally for easier access\\n\\n:::\\n\\n## Running the Web Server\\n\\nWith the server machine all set up, next is to run the playground web server and\\nthe database on this machine. I chose running the app and the database in docker\\nfor easier management. If you run it in other ways, you can skip this session,\\nmake the app run on the server, and skip ahead to the\\n[configuring DNS](#configuring-dns),\\n[configuring firewall with `ufw`](#configure-firewall-ufw), and\\n[configuring reverse proxy server `nginx`](#configure-reverse-proxy-server-nginx)\\nsection.\\n\\n### Why Docker?\\n\\nThere are several ways to run a server. You may run it as a process on the\\nmachine directly. This should be the simplest to get started. You can even run\\nthe server the same way as how you are running it locally. However, it will get\\nharder when managing versions of the apps and getting the runtime right. For\\nexample, my playground is an elixir server. If I want to update the Elixir or\\nErlang version, I need to make sure the same version is properly installed on\\nthe server machine as well. If I have another web server running on the same\\nmachine that needs another version of Elixir then I need to install some other\\nvirtual environment or shimming tools on the server as well. And if I ever want\\nto have more than one machine running the same app, then I need to update every\\nsingle machine to the same versions.\\n\\nI am probably still far from all these scaling issues, but there is nothing\\nstopping me from preemptively think about scaling issues. It gets harder to\\nmanage when more things are involved, if there is no isolation. To solve all the\\nabove issues, the most common solution is running apps in\\n[containers](https://www.docker.com/resources/what-container/).\\n\\nIf you do not know what containers are, you can think of them as a box that\\nprovide a mini computer environment for the things running inside. And this box\\nis completely isolated from other boxes or the world outside the box. The box is\\nlightweight, which means it is easy to create, start, stop or destroy, with\\nlower overhead compare to virtual machines. Furthermore, they are \\"standardized\\"\\nlike shipping containers. The same containers can be run in different\\nenvironment (Windows, Mac, Linux, etc.) with the docker engine installed. Any\\ncode in any tech stack can be run within a container, just like any things can\\nbe shipped on any cargo vessels, as long as they fit in the standardized\\nshipping containers. It solves the issue where an app need to build a native\\nversion for every runtime environment.\\n\\nThe overall flow for me to deploy playground right now is not very optimized,\\nbut works for me. Plus, I do not deploy frequently. I will go through them in\\ndetails below, but this is the higher level:\\n\\n1. Push code to GitHub and tag the commit I want to deploy\\n2. Pull code from the Hetzner VPS and checkout the tag\\n3. Build a new image in the VPS\\n4. Stop and then remove the old container\\n5. Start the new container\\n\\nThere are other tools and services to allow easier deployment, like\\n[Coolify](https://coolify.io/). You may find these useful if you are not\\ncomfortable working with docker and nginx directly, or want to make the process\\nmore optimize.\\n\\n### Pull Code\\n\\nFirst, I need to make sure my Hetzner VPS and my local machine have the same\\ncode. And the easiest way for me to copy them over is to push that code to\\nGitHub, then pull the same commit from GitHub.\\n\\nI chose not to use a docker repository, where I would need to first push a\\ndocker image for the new version, and then pull that image and run it. I already\\nhave a code repository. I can directly build the docker image with the source\\ncode in the server machine. Because it is just docker build, I do not need any\\nruntime and binary either. I only need to SSH into the VPS and run a script.\\n\\nIf you are able to push code to GitHub, I think you know how to pull code from\\nGitHub. The only difference, maybe, is to get familiar with the git CLI, if you\\nare used to Git with a GUI. The CLI is not that complicate for basic pull and\\ncheckout. I have some more resources in the\\n[Git page of this Wiki](https://wiki.ethanppl.com/computers/programming/git).\\n[Generate a new pair of SSH keys](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent)\\nin the Hetzner VM and add it to your GitHub account should make every thing\\nworks.\\n\\n### Building the Server Image\\n\\nWith Git set up, next is to install docker. Docker allow us to build the images\\nand run those images in containers. There are detailed documentation on how to\\ninstall docker, and\\n[here is the one for Ubuntu](https://docs.docker.com/engine/install/ubuntu/).\\nOne thing to pay attention for Linux is there are\\n[post-installation steps](https://docs.docker.com/engine/install/linux-postinstall/)\\nto manage user roles and permissions.\\n\\nTo run the app in a container, we need to build an image for it to run on. A\\ndocker image contains the code and data needed for the container to run. The\\ninstructions for building a docker image are specified in a\\n[docker file](https://docs.docker.com/reference/dockerfile/).\\n\\nI will not go into the specific details of setting up the Elixir build\\nenvironment and run time in this post, that will most likely be different from\\nwhat you need if you are not running an Elixir app. You will need to write your\\nown docker file or copy some templates for your tech stack. You can find the\\n[docker file for my playground app in the GitHub repository](https://github.com/ethanppl/playground/blob/main/Dockerfile)\\nfor reference.\\n\\nDocker image can be based on top of other docker images. For example,\\n[alpine](https://hub.docker.com/_/alpine/) is a lightweight Linux image to be\\nbased on. Which image to use depends on what apps you are running, there should\\nbe plenty of guides on how to build a docker image for the tech stack that you\\nare running on. For the playground app, since we are running an Elixir app, the\\nbase image is based on the\\n[elixir docker image](https://hub.docker.com/_/elixir).\\n\\nTo test the docker file, you can build it locally and run the container locally\\nto see if it works as expected. This is also why I set up my server environment\\ncloser to my local machine. It is easier to build and debug the image locally,\\nwhile having a higher likelihood all should still work on the server machine.\\n\\nSo, build the docker image at the root of the repository, where the `Dockerfile`\\nis. I like to tag the output image (`-t playground`), so it is easier to\\nreference later:\\n\\n```sh\\ndocker buildx build -t playground .\\n```\\n\\n:::note\\n\\nBuilding a docker image for the web server\\n\\n- Docker containers for isolation and easier deployment\\n- Write and test building the docker image locally\\n- Pull code from git and build the container image in the server machine\\n\\n:::\\n\\n### Running the Postgres Container\\n\\nMy server depends on a Postgres database. I ran this database also inside a\\ncontainer, with docker volume and custom bridge network set up. If you do not\\nneed a database, you may skip this section.\\n\\nAgain, I can run the Postgres database natively or as a docker container. I\\nchose running it in a docker container for the benefit of isolation. I knew I\\nwill run other services on the same machine that also need separate Postgres\\ndatabases. Having them isolated make things easier to control.\\n\\nDocker volumes and networking are the two important things to consider when\\nrunning a database in a container.\\n\\n#### Docker Volume\\n\\nFirst, when the database container is stopped or destroyed, we want to persist\\nits data. Otherwise, it\'s not a database.\\n[Docker volume](https://docs.docker.com/engine/storage/volumes/) is a great way\\nto do that. Volumes are managed by docker and the data will be preserved even\\nthe container is stopped or destroyed. Volume is the preferred way to store and\\nretrieve data in a container.\\n\\nFirst, create a volume to be used later:\\n\\n```sh\\ndocker volume create pgdata\\n```\\n\\n#### Docker Network\\n\\nSecond, as mentioned, containers are isolated. The playground app running in a\\ncontainer by default cannot connect to the Postgres database running in another\\ncontainer. There are generally two approaches to solve this issue, expose the\\ncontainer to the host network or create a user-defined\\n[docker network](https://docs.docker.com/engine/network/) to connect the two\\ncontainers.\\n\\nExposing to the host network means the container will share the host\'s network.\\nFor example, if the Postgres container is exposing the 5432 port to the host\\nnetwork, inside the machine, accessing `localhost:5432` will be the docker\\ncontainer. The advantage is this is easier to set up, just add the\\n`--network=host` flag, but then there is no isolation. Generally, any process\\nthat can access localhost will be able to access the localhost will be able to\\naccess the container. It is also impossible for two different Postgres\\ncontainers to share the same localhost 5432 port.\\n\\nOn the other hand, docker allows creating user-defined network. The default\\nnetwork driver is called\\n[bridge network](https://docs.docker.com/engine/network/drivers/bridge/). In\\nsimple terms, defining a custom bridge network creates a bridge between the\\ncontainers to communicate with each other. This solves what we need while\\nmaintaining the same isolation. Containers can also be attached and detached\\nfrom the bridge networks on the fly.\\n\\nTo create a network to be used later:\\n\\n```sh\\ndocker network create playgroundNetwork\\n```\\n\\n#### Running the Database\\n\\nIt takes one line to run the Postgres container\\n\\n```sh\\ndocker run\\n  --name postgres\\n  --env=POSTGRES_PASSWORD=ReplaceMe\\n  --env=POSTGRES_DB=playground_engine\\n  -v pgdata:/var/lib/postgresql/data\\n  -p 5432:5432\\n  -d\\n  postgres\\n```\\n\\n- The [name](https://docs.docker.com/reference/cli/docker/container/run/#name)\\n  of the container will be `postgres`\\n- The two\\n  [ENV variables](https://docs.docker.com/reference/cli/docker/container/run/#env)\\n  - The password for the superuser `postgres`\\n  - The default database name\\n  - [There are more ENV variables available to configure](https://hub.docker.com/_/postgres/)\\n- Use the `pgdata` volume created earlier and mount that to the\\n  `/var/lib/postgresql/data` path inside the container\\n- Expose 5432 port to the network\\n- `-d` to\\n  [detach](https://docs.docker.com/reference/cli/docker/container/run/#detach)\\n  the container process from the terminal window, otherwise closing the terminal\\n  will stop the container\\n- And finally `postgres` is the name of the image, which\\n  [you can find on docker hub](https://hub.docker.com/_/postgres/)\\n\\n#### Verify the Database is Running\\n\\nOnce connected, we can use `psql` to verify the database is up and running.\\n\\nMost likely, the base Ubuntu image does not come with `psql`, so it needs to be\\ninstalled:\\n\\n```sh\\nsudo apt install -y postgresql-client-common postgresql-client-16\\n```\\n\\nThen connecting to it:\\n\\n```sh\\npsql postgresql://postgres@localhost:5432/playground_engine\\n```\\n\\nYou will be prompted to input your password. Input the same password set above\\nin the `POSTGRES_PASSWORD` ENV variable. If connected successfully, it means the\\ndatabase is running well.\\n\\nIn my\\n[playground deployment notes](https://github.com/ethanppl/playground/blob/main/DEPLOYMENT.md),\\nyou will find lines where I set up DB roles and privileges. They are just\\npractices. Normally for a side project database there is no such need either. I\\nmainly referenced\\n[Securing your PostgreSQL DB with Roles & Privileges](https://rlopzc.com/posts/securing-your-postgresql-db-with-roles--privileges/)\\nto build these commands for creating roles and granting privileges.\\n\\nWith all that set, exit the `psql` session and back to the host machine, we add\\nthe Postgres container to the network created earlier:\\n\\n```sh\\ndocker network connect playgroundNetwork postgres\\n```\\n\\nThen, inspect the network to get the IP address of the Postgres container.\\n\\n```sh\\ndocker network inspect playgroundNetwork\\n```\\n\\nThere should be something like 127.18.0.2. Save it. It will be useful later to\\nconnect the playground container to the database.\\n\\n### Running the Server Container\\n\\nThen, we can deploy the Playground container. There are playground specific\\ncommands that is used because of Elixir Phoenix framework. Your server with a\\ndifferent tech stack will most likely require different ENVs. For example,\\nPhoenix framework provide a\\n[deployment guide](https://hexdocs.pm/phoenix/deployment.html). You may be able\\nto find similar documentation.\\n\\nFor playground, this docker run command is used:\\n\\n```sh\\ndocker run --name playground \\\\\\n  --network=playgroundNetwork \\\\\\n  --env=DATABASE_URL=\\"postgresql://playground_backend:password@172.18.0.2:5432/playground_engine\\" \\\\\\n  --env=MIGRATION_DATABASE_URL=\\"postgresql://playground_migrations:password@172.18.0.2:5432/playground_engine\\" \\\\\\n  --env=SECRET_KEY_BASE=\\"secret\\" \\\\\\n  --env=PHX_HOST=\\"playground.ethanppl.com\\" \\\\\\n  --env=ENV=\\"production\\" \\\\\\n  --env=SENTRY_DSN=\\"https://sentry.ethanppl.com\\" \\\\\\n  -p 4000:4000 \\\\\\n  -d\\n  playground\\n```\\n\\n- Name this container as `playground`\\n- The network is the `playgroundNetwork` created earlier\\n- Change the database role, password, IP address, and database name accordingly\\n- I have a separate role and user for schema migration, so a different\\n  `MIGRATION_DATABASE_URL`\\n- Set the `SECRET_KEY_BASE` to a secret generated from `mix phx.gen.secret`\\n- Set the `PHX_HOST` to the domain name being used\\n- Set the `ENV` to production\\n- The `SENTRY_DSN` is optional to track errors\\n- Expose port 4000\\n- `-d` to detach the process\\n- Run the `playground` image\\n\\nOnce ran, you should be able to confirm the container is running with\\n\\n```sh\\ndocker ps\\n```\\n\\nYou should be able to see the playground container is up and running.\\n\\nCheck the logs in the container to confirm it can connect to the database:\\n\\n```sh\\ndocker logs playground\\n```\\n\\nIf the app cannot connect to the database, double-check the IP address and port.\\nAs a tip, you can spin up a small container with the\\n[`alpine` image](https://hub.docker.com/_/alpine/), add this small container to\\nthe same network with the database, and you can use\\n[`docker exec`](https://docs.docker.com/reference/cli/docker/container/exec/) to\\ndebug and see if it can connect to the database in the network. If it works,\\nthen the database and docker network is working, it\'s the configuration or the\\nplayground server problem. If it does not, then maybe the database is not\\nrunning, or the docker bridge network is not working.\\n\\n:::note\\n\\nGetting everything running in docker:\\n\\n- Also run the Postgres database in container\\n- Use docker volume to persist the database storage\\n- Use docker network to allow connections between the web server container and\\n  the database container\\n- Run the container with the right environment variables\\n\\n:::\\n\\n## Configuring DNS\\n\\nDomain name system (DNS) allows anyone on the Internet to use\\n`playground.ethanppl.com` to find the IP address of the server hosting it, and\\nroute request there.\\n\\nI used Cloudflare to purchase my `ethanppl.com` domain, so logically I use their\\nDNS service. Their DNS service is free of charge.\\n\\nTo point `playground.ethanppl.com` to the Hetzner VPS, we will need to set up an\\n`A` record for the IPv4 address and an `AAAA` record for the IPv6 address. The\\nname of both records is `playground`. The content is the IPv4 and IPv6 address,\\nrespectively. I set the proxy status to true for both, but false also works.\\nKeep the time to live (TTL) as auto, which by default is 5 minutes.\\n\\nIf proxy is enabled, Cloudflare will expose their server IP address, and\\ninternally route traffic to the Hetzner VPS. It automatically offers some\\noptimization, caching and protection. Read more in\\n[Cloudflare documentation](https://developers.cloudflare.com/dns/proxy-status/).\\n\\n![Cloudflare DNS](./assets/self-host/cloudflare-dns.png)\\n\\nLater, we will require HTTPS for the domain. If proxy is enabled, we need to\\nchange the encryption mode from \\"Flexible\\" to \\"Full\\" or \\"Full (Strict)\\" in the\\nSSL/TLS page. By default, Cloudflare use \\"Flexible\\" mode which send request in\\nHTTP. If the server automatically redirects HTTP request to HTTPS requests, and\\nCloudflare forward that request as HTTP, creating an infinite redirect loop.\\nChange the encryption mode so that Cloudflare send request as HTTPS. Read more\\nabout this problem in\\n[Cloudflare documentation](https://developers.cloudflare.com/ssl/troubleshooting/too-many-redirects/#flexible-encryption-mode).\\n\\n:::note\\n\\nDNS:\\n\\n- `A` record for IPv4 and `AAAA` for IPv6\\n- If proxy with Cloudflare and requiring HTTPS later, change encryption mode in\\n  Cloudflare to \\"Full\\" or \\"Full (Strict)\\"\\n\\n:::\\n\\n## Configure firewall (`ufw`)\\n\\nWith DNS set up, we can configure the server to listen to the traffic from the\\nInternet.\\n\\nCheck the firewall setting in `ufw` to make sure our app can listen to web\\nserver traffic.\\n\\n```sh\\nsudo ufw status\\n```\\n\\nSome of the commands that might be helpful\\n\\n- `sudo ufw show user-rules`: display information of the running firewall\\n- `sudo ufw status verbose`: show config\\n- `sudo ufw enable`: enable ufw\\n- `sudo ufw default deny incoming`: by default disallow all incoming traffic\\n  from the Internet to the machine\\n- `sudo ufw default allow outgoing`: by default allow all outgoing traffic from\\n  the machine to the Internet\\n- `sudo ufw allow OpenSSH`: allow SSH, **this is important**, otherwise will not\\n  be able to SSH in\\n- `sudo ufw allow http`: allow HTTP\\n- `sudo ufw allow https`: allow HTTPS\\n- `sudo ufw allow in on docker0 from 192.168.1.0/24`: open ufw to docker for\\n  local network\\n- `sudo ufw allow in on docker0 from 10.8.0.0/24`: open ufw to docker for local\\n  network\\n- `sudo ufw allow in on docker0 from 172.20.0.0/16`: open ufw to docker for\\n  local docker subnet\\n- `sudo ufw allow 51820/udp`: allow UDP on port 51820 (this is not useful for\\n  playground but for the wireguard server I have)\\n\\nHere is the configuration I have\\n\\n```\\nTo                         Action      From\\n--                         ------      ----\\nOpenSSH                    ALLOW       Anywhere\\n80/tcp                     ALLOW       Anywhere\\n443                        ALLOW       Anywhere\\nAnywhere on docker0        ALLOW       192.168.1.0/24\\nAnywhere on docker0        ALLOW       10.8.0.0/24\\nAnywhere on docker0        ALLOW       172.20.0.0/16\\n51820/udp                  ALLOW       Anywhere\\nOpenSSH (v6)               ALLOW       Anywhere (v6)\\n80/tcp (v6)                ALLOW       Anywhere (v6)\\n443 (v6)                   ALLOW       Anywhere (v6)\\n51820/udp (v6)             ALLOW       Anywhere (v6)\\n```\\n\\n:::note\\n\\nFirewall\\n\\n- Allow SSH and HTTP connections\\n- Disallow traffic into other ports\\n\\n:::\\n\\n## Configure reverse proxy server (`nginx`)\\n\\nNginx is a lightweight server running on the machine. It makes it easy to host\\nmultiple domains on the same server. It can route the incoming traffic from the\\nInternet to the right server running on the machine based on the domain name.\\nFor example, anyone on the internet trying to talk to `playground.ethanppl.com`\\nwill be routed to the docker container running at port `4000` locally.\\n\\nThere are a lot more features supported by nginx, you may explore them on\\n[their documentation](https://nginx.org/en/docs/). The first thing is to get it\\nup and running.\\n\\n### Basics\\n\\nInstall nginx first.\\n[Here is the doc for installing on Ubuntu](https://nginx.org/en/linux_packages.html#Ubuntu).\\n\\nStart the nginx server:\\n\\n```sh\\nsudo systemctl start nginx\\n```\\n\\nThe configurations are stored in the `/etc/nginx` directory.\\n\\n```sh\\ncd /etc/nginx\\n```\\n\\nYou should find a `/etc/nginx/nginx.conf` file with some default configurations.\\n\\nYou may add new configurations in the `nginx.conf` file directly to test. But\\nfor better organization, I find it better to create a separate config file for\\neach server and include them in the main `nginx.conf`. For me, the default\\nconfiguration already includes a line of `include /etc/nginx/conf.d/*.conf;` in\\nthe `http` block. Adding a new `*.conf` file inside the `/etc/nginx/conf.d`\\ndirectory will work.\\n\\nCreate a new file `playground.conf` file in `/etc/nginx/conf.d`. The file name\\ndoes not matter, you can change it however you want.\\n\\nAdd the following config:\\n\\n```\\nserver {\\n   listen 80;\\n\\n   # Change this\\n   server_name playground.ethanppl.com;\\n\\n   location / {\\n      proxy_pass http://localhost:4000;\\n      proxy_ssl_server_name on;\\n\\n      # For web socket connections\\n      proxy_http_version 1.1;\\n      proxy_set_header Upgrade $http_upgrade;\\n      proxy_set_header Connection \\"Upgrade\\";\\n   }\\n}\\n```\\n\\nChange the `server_name` directive to the domain name of your web server. The\\n`server_name` directive is what nginx use to determine where to route the\\ntraffic. In the above configuration, anything requesting to\\n`playground.ethanppl.com` will go to `localhost:4000`.\\n\\nIf you are running the playground server, or anything requires web socket, the\\nthree lines for setting header and connection upgrade is required. It allows\\nupgrading an HTTP connection to a WebSocket connection. Read more about it in\\n[MDN docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Upgrade)\\nand explanation on setting up\\n[WebSocket proxying in nginx](https://nginx.org/en/docs/http/websocket.html).\\n\\nIf your site contains requirements for other communication protocol, worth\\nchecking nginx documentation to see if there are specific configurations needed.\\nIt is also a good way to learn how protocols run behind the scenes and what are\\ninvolved underlying the connections.\\n\\nThen, test that the nginx configurations are valid.\\n\\n```sh\\nsudo nginx -t\\n```\\n\\nIf all goes well, you should see the following lines being printed:\\n\\n```\\nnginx: the configuration file /etc/nginx/nginx.conf syntax is ok\\nnginx: configuration file /etc/nginx/nginx.conf test is successful\\n```\\n\\nOtherwise, follow the instructions printed to fix the configuration. It should\\ntell you where are the invalid value on which directive.\\n\\nOnce all good, reload the nginx server:\\n\\n```sh\\nsudo nginx -s reload\\n```\\n\\n### HTTPS\\n\\nHTTPS is almost compulsory nowadays. Some default browser settings would prevent\\nusers from accessing a site without HTTPS. I would like to share my site with\\npeople without them clicking \\"Proceed (unsafe)\\". Able to set up HTTPS for\\nself-hosted site is a must for me.\\n\\nFortunately, there are free service providing signing and issuing certificate\\nfor HTTPS. [Let\'s Encrypt](https://letsencrypt.org/) is a free certificate\\nauthority service by a nonprofit organization. In fact, some major static site\\nhosting on cloud providers like Render all uses Let\'s Encrypt behind the scene\\nto provide their automated SSL certificates.\\n\\nSetting up the certificates are pretty easy.\\n[Here is the guide](https://certbot.eff.org/instructions?ws=nginx&os=ubuntufocal)\\nfor using nginx on Ubuntu with Certbot. [Certbot](https://certbot.eff.org/) can\\nget free certificates and set the corresponding nginx configurations\\nautomatically.\\n\\nFor other platforms and setup, check\\n[Let\'s Encrypt Getting Started documentation](https://letsencrypt.org/getting-started/)\\nand [Certbot help page](https://certbot.eff.org/pages/help).\\n\\nFollow the instructions to install snap and use snap to install certbot. Run\\ncertbot and allow it to edit the nginx configurations directly.\\n\\n```sh\\nsudo certbot --nginx\\n```\\n\\nIt will automatically find all the domains without certificates, create a\\ncertificate and update the nginx configuration accordingly. Certbot provides a\\n`certonly` option to let you make the nginx configurations by hand. But in my\\nexperience, the bot is good, and it does not mess up the nginx configurations.\\n\\nTest that the configurations are all good: `sudo nginx -t`. And reload the\\nconfigurations again, `sudo nginx -s reload`.\\n\\nNow you should be able to connect to the site with HTTPS!\\n\\nIf you inspect the configuration file, you will see that lines marked with\\n`# managed by Certbot`. It added port 443 for SSL connection, added the\\n`ssl_certificate` directive and some related configurations. It also added an\\nautomatic redirect from HTTP to HTTPS. This is why we need to tell Cloudflare to\\nsend request with HTTPS when proxy through Cloudflare. Otherwise, it enters a\\nredirect loop.\\n\\n### HTTP2 and HTTP3\\n\\nHTTP2 and HTTP3 each has improvements over the application protocol to improve\\nlatency and reliability. Most of the time there should not be noticeable\\ndifference, especially our site is not demanding high bandwidth communication.\\nYou read more about HTTP2 and HTTP3 on the\\n[HTTP Page in this Wiki](/computers/network/http).\\n\\nTo enable HTTP2,\\n\\n- Add `http2 on` in the server configuration\\n\\nTo enable HTTP3,\\n\\n- Add `http3 on`\\n- Add `listen 443 quic reuseport` or just `listen 443 quic`.\\n  - Notice that if there are multiple servers using the same IP address and port\\n    in nginx, only one of them can do `reuseport`.\\n- Add `add_header Alt-Svc \'h3=\\":443\\"; ma=86400\'` in the location block\\n  - This is a response header to let the browser know that another location\\n    (alternative service (Alt-Svc)) is available for servicing with HTTP3 (h3)\\n- The port used by `quic` is recommended to be the same as `ssl`, hence 443\\n\\nThe final configuration should look something like this:\\n\\n```\\nserver {\\n   server_name  playground.ethanppl.com;\\n\\n   http2 on;\\n   http3 on;\\n\\n   location / {\\n      proxy_pass http://localhost:4000;\\n      proxy_ssl_server_name on;\\n\\n      # For web socket connections\\n      proxy_http_version 1.1;\\n      proxy_set_header Upgrade $http_upgrade;\\n      proxy_set_header Connection \\"Upgrade\\";\\n\\n      add_header Alt-Svc \'h3=\\":443\\"; ma=86400\';\\n   }\\n\\n   listen 443 ssl; # managed by Certbot\\n   listen 443 quic reuseport;\\n\\n   ssl_certificate /etc/letsencrypt/live/playground.ethanppl.com/fullchain.pem; # managed by Certbot\\n   ssl_certificate_key /etc/letsencrypt/live/playground.ethanppl.com/privkey.pem; # managed by Certbot\\n   include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\\n   ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\\n\\n}\\n\\nserver {\\n   if ($host = playground.ethanppl.com) {\\n      return 301 https://$host$request_uri;\\n   } # managed by Certbot\\n\\n\\n   listen       80;\\n   server_name  playground.ethanppl.com;\\n   return 404; # managed by Certbot\\n}\\n```\\n\\n:::note\\n\\nNginx\\n\\n- Based on the `server_name`, proxy the connection to the docker container\\n- Use Let\'s Encrypt and certbot to get a certificate and configure HTTPS\\n  automatically\\n- Add relevant configuration to support HTTP2 and HTTP3 connections\\n\\n:::\\n\\n## Monitoring\\n\\nI am not running mission-critical life savings web services, but it is still\\ngood to monitor what is going on in the server and alert me when things gone\\nwrong. I found some monitoring services online that are free for hobby projects.\\n\\n### Netdata\\n\\nI use [Netdata](https://www.netdata.cloud/) for monitoring the Hetzner server\\nand the containers. It has an agent to read the data and optionally upload to\\nNetdata cloud server for some nice visualizations. It includes basics like CPU,\\nmemory, storage and network data for the host machine. Additionally, it can also\\nshow the load for each container running in the machine.\\n\\n![Netdata System Overview](./assets/self-host/netdata-overview.png)\\n![Netdata Containers Metrics](./assets/self-host/netdata-containers.png)\\n\\nIt works out of the box. Create an account on Netdata Cloud, follow the prompt\\nto connect a node, pick Ubuntu and follow the instructions on screen to install\\nthe Netdata agent and all graphs worked. Email automations are automatically\\nconfigured to notify when things went wrong. However, configuring the\\nnotifications rules requires subscribing to a paid plan.\\n\\n:::tip\\n\\nIf you would like to subscribe to Netdata, here is my\\n[invite link](https://netdata.cello.so/m3g8ZJvzrI9) for 10% discount for the\\nfirst year.\\n\\n:::\\n\\n### Checkly\\n\\nAnother tool I used for checking uptime and response time is\\n[Checkly](https://www.checklyhq.com/). For free, there is a certain amount of\\nAPI calls and browser per month. What I do is just for every 30 mins to 1 hour,\\ncall my self-hosted services and make sure they return status 200.\\n\\n![Checkly](./assets/self-host/checkly.png)\\n\\nCheckly supports different location and interval to send the request. It also\\nallows different assertions like text/json response, and verify the response\\nmeet certain requirements. I kept it simple to assert for status 200, but there\\nare potential to configure it for more robust health checks.\\n\\n## Much More\\n\\nOther than monitoring, there are a lot more to try and experiment. I added my\\nown [plausible analytics server](https://plausible.io/),\\n[glitchtip](https://glitchtip.com/) error tracking server, and more. This blog\\nis already long. I may write about them in the future. All in all, the machine\\nis yours, and you can do whatever you want with it.\\n\\nThere are more to explore in the area of self-hosting. There are always more to\\ndo with security. This blog covered the basics like SSH authentication with keys\\ninstead of password, basic firewall set up with `ufw` and HTTPS for our server.\\nThere are more to do like not SSH into as root user by default and running\\ncontainers in rootless environment.\\n\\nBackup is also another important aspect for self-hosting. If you want to store\\nanything important, always backup regularly. Follow the\\n[3-2-1 backup rule](https://en.wikipedia.org/wiki/Backup#3-2-1_Backup_Rule),\\nwith 3 copies, 2 on different media types and 1 stored offsite. This is to\\nprevent any potential catastrophic error, be it human error, or disk corrupted,\\nelectricity disruption, virus and malware.\\n\\n## Summary\\n\\nThis setup has been running for 9 months now, and it requires little\\nmaintenance. I had a lot of fun running my own server and figuring out stuff\\nalong the way.\\n\\nThis blog went through my thought process on choosing the server machine,\\nrunning playground in docker, configuring database containers, DNS, nginx,\\nfirewall and monitoring tools. I believe it will be a never ending journey and I\\nhope this inspires people to try too. I am not someone particularly interested\\nin DevOps or server configurations, but this project gave me a better\\nunderstanding of the problem space.\\n\\nIf you would like to explore more,\\n[`awesome-selfhosted`](https://github.com/awesome-selfhosted/awesome-selfhosted)\\nis a list of software services available for hosting, and\\n[`awesome-sysadmin`](https://github.com/awesome-foss/awesome-sysadmin) is a list\\nof awesome open-source sysadmin resources.\\n\\n## References\\n\\nCheckout [self-hosting page](/computers/self-hosting) for more.\\n\\nMy setup is closest to this blog:\\n\\n- [My self-hosted websites architecture](https://cprimozic.net/blog/my-selfhosted-websites-architecture/)\\n  - OVH cloud, nginx reverse proxy, DNS & networking, external CDN for high\\n    traffic static sites\\n  - Hosting websites, databases, plausible for analytics, sentry for error\\n    alerts, personal utils\\n  - Handling security, monitoring, backup and disaster recovery\\n\\nOther blogs:\\n\\n- [Self-hosting in 2023](https://grifel.dev/decentralization/)\\n  ([HN](https://news.ycombinator.com/item?id=34860655))\\n  - Interesting read. Self-host a blog with Raspberry Pi, Coolify for deployment\\n    and DDClient to solve the problem of a dynamic IP\\n- [Self-hosted is awesome](https://pixeljets.com/blog/self-hosted-is-awesome/)\\n  - Hetzner setup, docker applications, nginx host, cloudflare DNS\\n- [Repurpose your old laptop into a home server](https://jakew.me/home-server/)\\n  - Ubuntu server, install docker, run Plex and secure remote connection with\\n    tailscale\\n\\nOther resources:\\n\\n- [awesome-selfhosted](https://github.com/awesome-selfhosted/awesome-selfhosted)\\n  \u2014 List of web applications that can be self-hosted\\n- [awesome-sysadmin](https://github.com/awesome-foss/awesome-sysadmin) \u2014 List of\\n  sysadmin resources\\n- [r/selfhosted](https://www.reddit.com/r/selfhosted/),\\n  [r/HomeServer](https://www.reddit.com/r/HomeServer/) \u2014 Reddit sub\\n- [slefh.st](https://selfh.st/) \u2014 Newsletter"},{"id":"/2025/02/23/js-array","metadata":{"permalink":"/blog/2025/02/23/js-array","source":"@site/blog/2025-02-23-js-array.md","title":"Reimplement all JavaScript Array Functions with while loops only","description":"Last month, out of curiosity, I reimplemented all 38 JavaScript Array functions","date":"2025-02-23T00:00:00.000Z","tags":[{"inline":true,"label":"Computers","permalink":"/blog/tags/computers"},{"inline":true,"label":"JavaScript","permalink":"/blog/tags/javascript"}],"readingTime":32.34,"hasTruncateMarker":true,"authors":[{"name":"Ethan Pang","url":"https://ethanppl.com/","imageURL":"https://github.com/ethanppl.png","key":"ethan","page":null}],"frontMatter":{"title":"Reimplement all JavaScript Array Functions with while loops only","tags":[{"label":"Computers","permalink":"computers"},{"label":"JavaScript","permalink":"javascript"}],"toc_min_heading_level":2,"toc_max_heading_level":3,"authors":"ethan"},"unlisted":false,"prevItem":{"title":"My $4/month self-hosted web server setup","permalink":"/blog/2025/05/25/self-host"},"nextItem":{"title":"How does the 6 digits number in multifactor authentication works?","permalink":"/blog/2024/12/28/mfa-totp"}},"content":"Last month, out of curiosity, I reimplemented all 38 JavaScript Array functions\\n(e.g. `.forEach()`, `.map()`, `.sort()`, etc.) with while loops only. As always,\\nI learned something as I work on the all the functions. Some features, edge\\ncases, considerations that I previously do not know about JavaScript.\\n\\n- [There are sparse arrays and the pain of handling them](/blog/2025-02-23-js-array.md#sparse-arrays)\\n- [Arrays are objects and its implications](/blog/2025-02-23-js-array.md#arrays-are-objects)\\n- [What copy of a reference in JavaScript actually means](/blog/2025-02-23-js-array.md#copy-of-a-reference)\\n- [What are iterators and generators](/blog/2025-02-23-js-array.md#iterator-and-generator)\\n- [Different kinds of equality in JavaScript](/blog/2025-02-23-js-array.md#equality)\\n\\nOther than that, there are some less-known functions that I discovered, at least\\nI have not used them before until now, like `.copyWithin()`, `.splice()` and\\n`.with()`.\\n\\nTo be honest, most of the implementation is tedious and repetitive. A lot of\\neffort goes into handling edge cases, which are the interesting things I\\nlearned. The implementation is not as interesting compare to random things I\\nlearned, so I will focus on sharing the lessons first. But if you really want\\nto, you can skip to the\\n[implementation considerations](/blog/2025-02-23-js-array.md#implementation-considerations)\\nwhere I explained the setup, how some functions are implemented, especially some\\ninteresting one like `.flat()` and `.sort()`.\\n\\nThe full code is available in [this repo](https://github.com/ethanppl/js-array).\\n\\n\x3c!-- truncate --\x3e\\n\\n## What I learned\\n\\n### Sparse Arrays\\n\\nThe first thing I discovered, and the major source of pain in this experiment is\\nsparse arrays. This means an array can have empty slots in between. Empty items\\nare different from `undefined` or `null`. `undefined` in an array is not empty\\nitems. Empty slots are just empty. You can define sparse arrays like this:\\n\\n```js\\nlet a = [1, , 3];\\nconsole.log(a);\\n// [1, <empty>, 3]\\n```\\n\\nOr if you set the length of an array that is larger than its original length,\\nthe new items are all empty.\\n\\n```js\\nlet a = [1];\\na.length = 2;\\nconsole.log(a);\\n// [1, <empty>]\\n```\\n\\nBut if you access an empty item with the square bracket, it will return\\n`undefined`.\\n\\n```js\\nlet a = [1, , undefined];\\nconsole.log(a[0]); // 1\\nconsole.log(a[1]); // undefined\\nconsole.log(a[2]); // undefined\\n```\\n\\nSo, the only way to know if an index is an empty slot, you use the `in`\\noperator. If it returns false, then it is empty.\\n\\n```js\\nlet a = [1, , undefined];\\nconsole.log(0 in a); // true\\nconsole.log(1 in a); // false\\nconsole.log(2 in a); // true\\n```\\n\\nTo make an item empty, you cannot reassign \\"an empty value\\". You have to delete\\nit from the array.\\n\\n```js\\nlet a = [1];\\nconsole.log(a); // [1]\\n\\ndelete a[1];\\nconsole.log(a); // [<empty>]\\n```\\n\\nThere are many more tricky things that comes with sparse arrays. For example,\\nmost of the functions that take a callback like `.forEach()`, `.filter()`, and\\n`.reduce()` will skip empty items in the array. But despite it skips invoking\\nthe callback, functions like `.map`, `.sort()` and `.reverse()` will preserve\\nthe empty items in their output.\\n\\n```js\\nconst out = [1, , 3].map((e) => {\\n  console.log(e);\\n  return e ** e;\\n});\\nconsole.log(out);\\n// 1\\n// 3\\n// [1, <empty>, 27]\\n```\\n\\nFunctions like `.at()` on the other hand treat empty as `undefined`. And newer\\nfunctions that creates a copy of the original array, like `.toSorted()` and\\n`.toReversed()`, converts empty items to `undefined`. Yes, it is pretty\\ninconsistent.\\n\\n```js\\nconsole.log([1, , 3].at(1));\\n// undefined\\n\\nconsole.log([1, , 3].toReversed());\\n// [3, undefined, 1]\\n```\\n\\nAlso, `.sort()` takes a compare function to sort the elements. But empty items\\nor `undefined` are not invoked. All undefined and empty items are sorted to the\\nend of the array, with `undefined` comes first and then empty items.\\n\\n```js\\nconsole.log([1, , 3, undefined, 2].sort());\\n// [1, 2, 3, undefined, <empty>]\\n```\\n\\nI did not know that arrays can have empty slots that is different from\\n`undefined`. I thought `undefined` means empty previously. I cannot think of a\\nway that empty arrays are useful, maybe except for a potential marginal gain in\\nmemory. Anything sparse arrays is useful for can be replaced by having\\n`undefined` as the value. In addition, `delete` and `in` operation is not what\\ndevelopers are used to when dealing with arrays. I do not think using sparse\\narrays is a good practice.\\n\\n### Arrays are Objects\\n\\nThe reason why you can use `delete` and `in` to check whether an item is empty\\nin an array, is because arrays are just objects. The index and value in an array\\nis a key value pair. The array object implements some helper that comes with\\nthis object to support the array functionality. And in fact, functions, sets, or\\nstrings are also objects. They can inherit methods and properties.\\n\\n```js\\nlet a = [1, 2, 3];\\nconsole.log(typeof a);\\n// \'object\'\\n\\nlet f = () => {};\\nconsole.log(typeof f);\\n// \'object\'\\n```\\n\\nTherefore, when the length of the array is modified to be larger than original,\\nthe key does not exist yet, hence the value is empty and the array is sparse. On\\nthe other hand, when the length is shortened, the array object automatically\\nclean up keys that are equal or larger than the length.\\n\\nSome consequences of Array being an object are the time complexity of these\\nfunctions. For example, accessing any value of an array by index is O(1) because\\nit is just a key value store underlying. This is different from lists in some\\nlanguages that are linked lists under the hood, linked list usually requires\\ntraversing the list from the start to access an item by index.\\n\\nAnother interesting consequences of time complexity is `.pop()` is O(1) while\\n`.shift()` is O(n). `.pop()` removes the last item in the array, and `.shift()`\\nremoves the first item in the array. `.pop()` is O(1) because it only needs to\\nremove the last item, and the length of the array is decremented by 1.\\n`.shift()` is O(n) because it needs to remove the first item, and all the other\\nitems need to be shifted to one index earlier.\\n\\n### Copy of a Reference\\n\\nIn JavaScript, objects are neither pass by value nor pass by reference, it is\\ncalled copy of a reference. I knew there is something different but never able\\nto remember it until now.\\n\\nFirst, in language with pointer, like c++, pass by value means the variable is\\ncopied to another place in the memory. Modifying it in the function does not\\nchange the original copy of the variable that is passed in. On the other hand,\\npass by reference means the variable is not copied, but the reference to the\\nvariable is passed in. Modifying it in the function will change the original\\nvariable outside the scope of the function.\\n\\nFor JavaScript, it is a bit different. It is called copy of a reference. Kind of\\nlike a mixture of the two. When you pass an object to a function, you are\\npassing a copy of the reference to the object. This means if you change the\\nproperties of the object in the function, it will also change the object outside\\nthe function. But if you reassign the object to a new object, it will not change\\nthe object outside the function.\\n\\n```js\\nlet a = [1, 2, 3];\\n\\nconsole.log(a); // [1, 2, 3]\\n\\nlet foo = (arr) => {\\n  arr[0] = 4;\\n  console.log(arr); // [4, 2, 3]\\n\\n  arr = [5, 6, 7];\\n  console.log(arr); // [5, 6, 7]\\n};\\n\\nfoo(a);\\n\\nconsole.log(a); // [4, 2, 3]\\n```\\n\\nI knew this before, but now I finally can remember it. This is important because\\nsome functions like `.map()` and `.filter()` will return a new array and do not\\nmodify the original array. But some functions like `.sort()` and `.reverse()`\\nmodify the original array.\\n\\n### Iterator and Generator\\n\\nI learned about iterators and generators when I have to implement `.entries()`,\\n`.keys()`, and `.values()`. I have never used them, but now I learned what they\\nare, what iterators and generators mean.\\n\\nIterator is an object that has a `next()` method that returns an object with\\n`value` and `done` properties. The `value` is the next value in the iteration,\\nand `done` is a boolean that indicates whether the iteration is done.\\n\\n- `.entries()`: iterator that returns an array with the index and value of each\\n  item\\n- `.keys()`: iterator that returns the index of each item\\n- `.values()`: iterator that returns the value of each item\\n\\nFor example,\\n\\n```js\\nlet a = [\\"a\\", \\"b\\", \\"c\\"];\\n\\nlet entries = a.entries();\\nconsole.log(entries.next()); // { value: [0, \'a\'], done: false }\\nconsole.log(entries.next()); // { value: [1, \'b\'], done: false }\\nconsole.log(entries.next()); // { value: [2, \'c\'], done: false }\\nconsole.log(entries.next()); // { value: undefined, done: true }\\n\\nlet keys = a.keys();\\nconsole.log(keys.next()); // { value: 0, done: false }\\nconsole.log(keys.next()); // { value: 1, done: false }\\nconsole.log(keys.next()); // { value: 2, done: false }\\nconsole.log(keys.next()); // { value: undefined, done: true }\\n\\nlet values = a.values();\\nconsole.log(values.next()); // { value: \'a\', done: false }\\nconsole.log(values.next()); // { value: \'b\', done: false }\\nconsole.log(values.next()); // { value: \'c\', done: false }\\nconsole.log(values.next()); // { value: undefined, done: true }\\n```\\n\\nGenerators on the other hand is a function that returns an iterator. It is\\ndefined with an asterisk `function*`. Inside a generator, you can use the\\n`yield` keyword to return a value for each `next()` call on the iterator. The\\nfunction will pause at the `yield` keyword, and resume when the `next()` method\\nis called again. It took me a while to understand how it works, but it is a\\npowerful tool to create custom iterators. I used generators to implement all 3\\nfunctions.\\n\\nFor example, to implement something that works like `.values()` is just:\\n\\n```js\\nfunction* values(array) {\\n  let i = 0;\\n  while (i < array.length) {\\n    yield array[i++];\\n  }\\n}\\n```\\n\\nGenerators is a very simple and neat way to create iterators. One tricky thing\\nwhen implementing the three iterators is sparse arrays are treated as undefined.\\nSo `.keys()` will return the index of the empty items, and `.values()` will\\nreturn `undefined` for the empty items.\\n\\n### Using `.call()`\\n\\nWhile implementing functions like `.map()` that takes a callback function, I\\nrealize it also take a second argument that is call `thisArg`. For example,\\ngiven a function `foo` used in `array.map(foo)`, if you call `this` in the\\ncallback function `foo`, the value of `this` is undefined. And in non-strict\\nenvironment `undefined` will be replaced by `globalThis`. You may read more\\nabout it in the\\n[MDN docs](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array#iterative_methods).\\n\\nI do not care that much about the correctness of the `this` value here, but at\\nleast I do want to know how to specify a `this` value when calling a function. I\\ndiscovered three functions provided by the Function object prototype, `.call()`,\\n`.apply()` and `.bind()`. All functions in JavaScript inherit these three\\nmethods. Out of all the tutorial I read, I think W3Schools has the most clear\\nand concise explanation you can check:\\n\\n- `.call()`: Calls a function with a given `this` value and arguments\\n  ([W3Schools](https://www.w3schools.com/js/js_function_call.asp))\\n- `.apply()`: Calls a function with a given `this` value and arguments as an\\n  array ([W3Schools](https://www.w3schools.com/js/js_function_apply.asp))\\n- `.bind()`: Returns a new function with a given `this` value\\n  ([W3Schools](https://www.w3schools.com/js/js_function_bind.asp))\\n\\nAnd this is how I make use of `.call()` in my implementation:\\n\\n```js\\n// For example .map()\\n(array, callback, thisArg) => {\\n  let output = [];\\n\\n  // loop the array\\n  let i = 0;\\n  while (i < array.length) {\\n    // Skip invoke on empty element, but still create empty element\\n    if (i in array) {\\n      // Using call to specify thisArg\\n      // instead of just callback(array[i], i, array)\\n      output[output.length] = callback.call(thisArg, array[i], i, array);\\n    } else {\\n      output.length++;\\n    }\\n    i++;\\n  }\\n\\n  return output;\\n};\\n```\\n\\nI did not test it and I doubt it actually works because I switched my\\nimplementations to be a module with functions rather than methods in a class (I\\nwill explain [below](#the-setup)). The `this` object might not apply in that\\ncase. But nevertheless, I learned about `.call()`, `.apply()` and `.bind()`.\\n\\n### Equality\\n\\nAs you might have already known, what is considered \\"equal\\" in JavaScript is\\ntricky. There are loosely equal (`==`) and strictly equal (`===`). In these\\nArray functions, there are also subtle differences between some functions when\\ntalking about what is \\"equal\\" to what. One examples is using `.indexOf()` and\\n`.includes()` to find an element in an array.\\n\\nThere are a few ways to determine if an element is in array. You can use\\n`.find()` or `.findIndex()` which takes a callback testing function to determine\\nif the element is what you are looking for, which you can control how the\\nequality comparison works. But if you do not want to write a callback, you can\\nuse `.indexOf()` to find an index that equals to the provided value (-1 if not\\nfound). Or, you can use `.includes()` to check if the array includes the\\nprovided value (false if not found). However, there is a subtle difference\\nbetween the equality in `.indexOf()` and `.includes()`.\\n\\n`.indexOf()` uses\\n[strict equal](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Strict_equality)\\n(`===`). Strict equality (`===`) is different from equality (`==`) where types\\nare also checked. Additionally, unlike `null` or `undefined`, `NaN` is not\\nstrictly equal to itself. So searching for `NaN` in an array with `.indexOf()`\\nwill always be -1. This design where `NaN` is not equal to itself is consistent\\nwith a lot of other languages and follows the\\n[IEEE 754 Standard](https://en.wikipedia.org/wiki/NaN#Comparison_with_NaN).\\n\\n```js\\nnull === null; // true\\nundefined === undefined; // true\\nNaN === NaN; // false\\n\\n[NaN].indexOf(NaN); // -1\\n```\\n\\nHowever, `.includes()` uses\\n[same-value-zero equality](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Equality_comparisons_and_sameness#same-value-zero_equality).\\nValues of zero are all considered to be equal, where `0` is equal to `-0` and\\n`NaN` is also equal to `NaN`. I referenced the implementation of `sameValueZero`\\nfrom the MDN docs linked above.\\n\\n```js\\nsameValueZero(0, 0); // true\\nsameValueZero(NaN, NaN); // true\\n\\n[NaN].includes(NaN); // true\\n```\\n\\nSo if you need to check if there is `NaN` in an array, you should use\\n`.includes()` instead of `.indexOf()`. If you want to read more about equality\\nin JavaScript,\\n[this MDN page](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Equality_comparisons_and_sameness)\\nexplains well with a table listed what is or is not equaled in each way of\\nevaluating equality.\\n\\nBy the way, another subtle difference is `.indexOf()` skips empty slots in\\nsparse arrays while `.includes()` treats empty slots as `undefined`. And all the\\n`find...` methods like `.find()` and `.findIndex()` callback function is invoked\\nfor every index, unlike rest of the iterative methods like `.map()` and\\n`.forEach()` that skips empty slots. Yet another edge cases with sparse arrays.\\n\\n```js\\n[,].indexOf(undefined); // -1\\n[,].includes(undefined); // true\\n```\\n\\n### Negative Indexes\\n\\nSome other things I learned included most of the methods that take an index as\\ninput supports negative index. For example, you can do `array.at(-1)` to get the\\nlast element, but you cannot do `array[-1]` which is equivalent to `array[\\"-1\\"]`\\n(which most likely is `undefined`).\\n\\nAnd each function also has special handling for index that is less than\\n`-array.length` or greater than `array.length`. For example, `.at()` returns\\n`undefined` if the index is outside the range from `-array.length` to\\n`array.length - 1`.\\n\\nThere are more complicated examples like `.slice()`, which is a function takes a\\nstart index and end index and slice the array. If the start index is a negative\\nindex, it does the conversion to count from the end of the array. But if that\\nstart index is less than `-array.length`, it uses 0 as the start index. And vice\\nversa for the end index, if greater than `array.length` it uses `array.length`\\nas the end index. And for these functions that takes two indexes, it also has a\\nspecial condition handling the order of the indexes. For `.slice()`, if the end\\nindex is earlier than the start index after the conversion, it returns an empty\\narray. If this sounds confusing, I agree. I suggest read again in point form in\\nthe\\n[MDN docs](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/slice#parameters).\\n\\n### Locales\\n\\nI also learned about locale while reading about `.toLocaleString()`. It helps\\nconvert number, date, letter formats, etc. Probably going too far away from\\nArrays, but still, I didn\'t know JavaScript supports this many variations.\\n\\n```js\\n[1, 2, 3].toLocaleString(\\"en-US\\", { style: \\"currency\\", currency: \\"USD\\" });\\n// \'$1.00,$2.00,$3.00\'\\n[1, 2, 3].toLocaleString(\\"en-US\\", { style: \\"currency\\", currency: \\"AUD\\" });\\n// \'A$1.00,A$2.00,A$3.00\'\\n[1, 2, 3].toLocaleString(\\"en-US\\", { style: \\"currency\\", currency: \\"EUR\\" });\\n// \'\u20ac1.00,\u20ac2.00,\u20ac3.00\'\\n[1, 2, 3].toLocaleString(\\"en-US\\", { style: \\"currency\\", currency: \\"JPY\\" });\\n// \'\xa51,\xa52,\xa53\'\\n```\\n\\nFor more you can read, again,\\n[MDN docs on the `Intl` global object](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Intl).\\n\\n### Less known functions\\n\\nThere are a few functions that I think are less known. At least I have not used\\nthem before and would like to share.\\n\\n#### [`.copyWithin()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/copyWithin)\\n\\n```js\\ncopyWithin(target, start);\\ncopyWithin(target, start, end);\\n```\\n\\n- It is used to copy elements with in the array by specifying the indexes\\n- It takes three indexes as arguments: target, start and end index\\n- It copies elements within start to end, to the target index\\n- It modifies the array and also return the resulting array\\n\\n```js\\n[\\"a\\", \\"b\\", \\"c\\", \\"d\\", \\"e\\"].copyWithin(1, 3);\\n// Copy the element at index 3 to index 1\\n// [\\"a\\", \\"d\\", \\"c\\", \\"d\\", \\"e\\"]\\n\\n[\\"a\\", \\"b\\", \\"c\\", \\"d\\", \\"e\\"].copyWithin(1, 2, 5);\\n// Copy the elements index 2-5 to index 1\\n// [\\"a\\", \\"c\\", \\"d\\", \\"e\\", \\"e\\"]\\n```\\n\\nI am not sure when is it useful. I guess when there is something need to\\nrearrange elements within an array in such a way.\\n\\n#### [`.splice()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/splice)\\n\\n```js\\nsplice(start);\\nsplice(start, deleteCount);\\nsplice(start, deleteCount, ...items);\\n```\\n\\n- It is used to delete some elements, and insert some new items at where\\n  elements are deleted\\n- It is like a combination of `.split()`, `.slice()` and `.concat()`\\n- It takes three arguments: starting index, delete count and list of new items\\n- It modifies the array and return the deleted elements\\n- If the delete count is not specified, it deletes till the end\\n\\n```js\\nconst a = [\\"a\\", \\"b\\", \\"c\\", \\"d\\", \\"e\\"];\\n// Delete starting at index 1 and till the end\\nconsole.log(a.splice(1)); // [\'b\', \'c\', \'d\', \'e\']\\nconsole.log(a); // [\'a\']\\n\\nconst b = [\\"a\\", \\"b\\", \\"c\\", \\"d\\", \\"e\\"];\\n// Delete 2 element starting at index 1\\nconsole.log(b.splice(1, 2)); // [\'b\', \'c\']\\nconsole.log(b); // [\'a\', \'d\', \'e\']\\n\\nconst c = [\\"a\\", \\"b\\", \\"c\\", \\"d\\", \\"e\\"];\\n// Delete 2 element starting at index 1\\n// And insert \\"m\\" and \\"n\\" in to where elements are deleted\\nconsole.log(c.splice(1, 2, \\"i\\", \\"j\\", \\"k\\")); // [\'b\', \'c\']\\nconsole.log(c); // [\'a\', \'i\', \'j\', \'k\', \'d\', \'e\']\\n```\\n\\nThis is a useful and efficient way to remove or insert items in the middle of\\nthe array, despite its functionality is not obvious from the name.\\n\\n#### [`.shift()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/shift) and [`.unshift()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/unshift)\\n\\n- `.shift()` is like `.pop()` but removes the first element instead of the last\\n  element\\n- `.unshift()` is like `.push()` but inserts the elements at the beginning of\\n  the array\\n- I also learned that both `.unshift()` and `.push()` can take more than 1\\n  element\\n- And I also learned that both `.unshift()` and `.push()` returns the new length\\n  of the array\\n\\n```js\\nconst a = [1, 2, 3, 4, 5];\\nconsole.log(a.pop()); // 5\\nconsole.log(a); // [1, 2, 3, 4]\\n\\nconst b = [1, 2, 3, 4, 5];\\nconsole.log(b.shift()); // 1\\nconsole.log(b); // [2, 3, 4, 5]\\n\\nconst c = [1, 2, 3, 4, 5];\\nconsole.log(c.push(6, 7)); // 7\\nconsole.log(c); // [1, 2, 3, 4, 5, 6, 7]\\n\\nconst d = [1, 2, 3, 4, 5];\\nconsole.log(d.unshift(-1, 0)); // 7\\nconsole.log(d); // [-1, 0, 1, 2, 3, 4, 5]\\n```\\n\\nAnd because how [arrays are objects](#arrays-are-objects) behind the scene,\\n`.pop()` is O(1) but `.shift()` is O(n), as explained above.\\n\\n#### [`.toReversed()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/toReversed), [`.toSorted()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/toSorted) and [`.toSpliced()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/toSpliced)\\n\\nThere are `.reverse()`, `.sort()`, and `.splice()` that modify the array in\\nplace. There are also `.toReversed()`, `.toSorted()` and `.toSpliced()` that are\\nfunctionally the same but create a new array instead of modifying the original\\none.\\n\\nThere are also subtle difference in the to... version. These methods never\\nproduce sparse array. They convert empty slots into `undefined`, while the\\noriginal `.reverse()`, `.sort()` and `.splice()` do not. I really wanted to know\\nwhy there is this difference and I went back to the\\n[original TC39 array by copy proposal](https://github.com/tc39/proposal-change-array-by-copy).\\nIn the end, I found\\n[this answer](https://github.com/tc39/proposal-change-array-by-copy/issues/8#issuecomment-817763412).\\nIn summary, these functions either are consistent with their counterpart that\\ntreats empty slots as empty slots, or be consistent with all other features\\nsince ES6 where they do not produce sparse arrays. So either way is breaking\\nconsistency, and they decided to stay consistent with the ES6 standard.\\n\\n```js\\n[1, 2, 3, ,].reverse(); // [<empty>, 3, 2, 1]\\n[1, 2, 3, ,].toReversed(); // [undefined, 3, 2, 1]\\n```\\n\\nThere are\\n[repeated discussion](https://github.com/tc39/proposal-change-array-by-copy/issues/101)\\nabout these inconsistencies in the proposal, it\'s an interesting read. It shows\\nhow many problems sparse arrays create for JavaScript language designers.\\n\\n#### [`.with()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/with)\\n\\n```js\\nwith(index, value)\\n```\\n\\n- `.with()` creates a new array with 1 element changed\\n- It is like the copying version of the bracket assignment `array[3] = \'a\'`\\n  notation\\n- It is added as part of the same\\n  [array by copy proposal](https://github.com/tc39/proposal-change-array-by-copy),\\n  but not using the same to... naming pattern, and\\n  [people did ask why](https://github.com/tc39/proposal-change-array-by-copy/issues/103)\\n\\n```js\\nconst a = [1, 2, 3];\\nconst b = a.with(1, 0);\\nconsole.log(a); // [1, 2, 3]\\nconsole.log(b); // [1, 0, 3]\\n```\\n\\n## Implementation Considerations\\n\\nSo that is mostly the things that I learned while working on this little\\nchallenge. If you still find it interesting, here is how I actually did it, and\\nhow I test it to ensure at least I have some certainty a majority of the\\nfunctionality correct.\\n\\n[Here is the link to the repo](https://github.com/ethanppl/js-array) if you are\\ninterested.\\n\\n### The setup\\n\\nThe major change I made is I wrote an object (`MyArray`) that contains functions\\nas parameters (e.g. `MyArray.at(array, 0)`), rather than defining those\\nfunctions as methods of an object (e.g. `array.at(0)`). Therefore, the first\\nargument of all the functions is always the input array. With that, I do not\\nneed to override the original methods. The built-in Array class is still used to\\nconstruct the array, but none of the prototype functions are modified or used.\\n\\n```js\\nconst array = [\\"a\\", \\"b\\", \\"c\\"];\\n\\n// original function\\nconst expected = array.join();\\n\\n// my function\\nconst actual = MyArray.join(array);\\n```\\n\\nThis makes it easier to test too. The `actual` value can be directly compared\\nwith the `expected` value.\\n\\nFor functions that modify the array instance, I can use `Array.from()` to create\\ncopies and compare.\\n\\n```js\\nconst array = [\\"c\\", \\"b\\", \\"a\\"];\\nconst expected = Array.from(array);\\nconst actual = Array.from(array);\\n\\nexpected.sort();\\nMyArray.sort(actual);\\n```\\n\\nI used [bun](https://bun.sh/) to run and test the code. It is fast, simple to\\nuse, support TypeScript, and provide a test runner out of the box.\\n\\nIn the project, I have to rely on some basic properties of the Array object. I\\nneed to get and set the `.length` property. As far as I can tell, that is the\\nonly way to get the length and manipulate the length. I use angle brackets `[]`\\nto access and assign items in the array. Also, with the `in` and `delete`\\noperator to check if an item exists and remove the items respectively. And last\\nbut not least, `while` to loop through the array.\\n\\nAt first, I thought of using `Array.reduce` to replicate all functionality of\\nother functions. It is inspired by functional programming language that a\\n`reduce` should be able to replicate all operations done recursively on a list.\\nBut once I learned about [sparse arrays](#sparse-arrays) and\\n[copy of a reference](#copy-of-a-reference), I realize it is near impossible if\\nnot actually impossible to do so. So I changed my mind and use a `while` loop\\ninstead. Why not `for` loop you may ask? Because then there is `for ... of` loop\\nand that is using the iterator behind the scene without the need of an index.\\nJust for the implementation to be more simple and raw, I decided to iterate with\\nan index instead, using a single keyword, `while`. And thus hopefully a more\\ncatchy blog title :P\\n\\nAs I said, most of the implementation are just tedious. They are especially\\ntedious when multiple functions share similar functionalities.\\n\\n### Similar functions\\n\\n`.find()`, `.findIndex()`, `.findLast()`, and `.findLastIndex()` are all very\\nsimilar. The difference is only whether it loops from the start or from the end,\\nand whether it returns the element or the index once the callback return true.\\n\\n```js\\n{\\n  find: <T>(\\n    array: Array<T>,\\n    callback: (element: T, index: number, array: Array<T>) => boolean,\\n    thisArg?: any\\n  ) => {\\n    let i = 0;\\n\\n    // loop the array\\n    // find does not skip empty value, but behave the same as undefined\\n    while (i < array.length) {\\n      const result = callback.call(thisArg, array[i], i, array);\\n\\n      if (result) {\\n        return array[i];\\n      }\\n      i++;\\n    }\\n\\n    return undefined;\\n  },\\n}\\n```\\n\\nOnce I learned iterators and generators, `.entries()`, `.keys()`, and\\n`.values()` are very similar. The only difference is the return value.\\n\\n```js\\n{\\n  entries: function* entries<T>(array: Array<T>): ArrayIterator<[number, T]> {\\n    let i = 0;\\n    while (i < array.length) {\\n      yield [i, array[i++]];\\n    }\\n  },\\n}\\n```\\n\\n`.some()` and `.every()` is like the opposite of each other. They both skip\\nempty element in sparse array. And one key thing is they both return early when\\n`.some()` finds true, or `.every()` finds false.\\n\\n```js\\n{\\n  every: <T>(\\n    array: Array<T>,\\n    callback: (element: T, index: number, array: Array<T>) => boolean,\\n    thisArg?: any\\n  ) => {\\n    let i = 0;\\n    let every = true;\\n\\n    // loop the array\\n    while (i < array.length) {\\n      // Skip empty element\\n      if (i in array) {\\n        const result = callback.call(thisArg, array[i], i, array);\\n\\n        if (!result) {\\n          // If one is false, stop looping\\n          every = false;\\n          break;\\n        }\\n      }\\n      i++;\\n    }\\n\\n    return every;\\n  },\\n}\\n```\\n\\nDespite some differences on what is returned, iterative functions like\\n`.filter()`, `.forEach()`, `.map()`, `.reduce()`, and `.reduceRight()` are all\\nsimilar. They all skip empty elements in sparse array, and use `callback.call()`\\nto invoke the callback. The only difference is handling the output returned.\\n\\n```js\\n{\\n  filter: <T>(\\n    array: Array<T>,\\n    callback: (element: T, index: number, array: Array<T>) => boolean,\\n    thisArg?: any\\n  ) => {\\n    let i = 0;\\n    let output: Array<T> = [];\\n\\n    // loop the array\\n    while (i < array.length) {\\n      // Skip empty element\\n      if (i in array) {\\n        const result = callback.call(thisArg, array[i], i, array);\\n\\n        if (result) {\\n          output[output.length] = array[i];\\n        }\\n      }\\n      i++;\\n    }\\n\\n    return output;\\n  },\\n}\\n```\\n\\nBut out of all the functions, I find `.flat()` and `.sort()` particularly\\ninteresting to tackle.\\n\\n### `.flat()`\\n\\n`.flat()` is interesting because it is a very good application of recursion.\\n\\nThe `.flat()` function takes an optional depth argument that defaults to 1,\\nspecifying how many layer to flatten recursively.\\n\\n```js\\n{\\n  flat: <T>(array: Array<T>, depth: number = 1): Array<T> => {\\n    return doFlat([], array, depth);\\n  },\\n}\\n```\\n\\nI first created a `doFlat` helper function that takes 2 arrays and the depth as\\nthe arguments. The idea being the first array is the output array, and the\\nsecond array is the input array getting flatten, and the depth is the current\\ndepth.\\n\\nThe `doFlat` function works like this:\\n\\n1. Loop through the array\\n2. If the element is an array, and the depth is not 0 yet, recursively call\\n   `doFlat` with the same output array, the current element as the input array,\\n   and one less depth\\n3. If the element is not an array, push it to the output\\n\\n```js\\nconst doFlat = (output: Array<any>, elements: Array<any>, depth: number) => {\\n  let i = 0;\\n  while (i < elements.length) {\\n    if (i in elements) {\\n      if (Array.isArray(elements[i]) && depth > 0) {\\n        doFlat(output, elements[i], depth - 1);\\n      } else {\\n        output[output.length] = elements[i];\\n      }\\n    }\\n    i++;\\n  }\\n\\n  return output;\\n};\\n```\\n\\nIf you think of the nested array as trees, this is like a\\n[depth first search](https://en.wikipedia.org/wiki/Depth-first_search) approach.\\nFor every array, flatten it until the specified depth, then continue to append\\nto the output. I personally find this solution quite simple and elegant.\\n\\n### `.sort()`\\n\\n`.sort()` sorts the array in place, i.e. it modifies the original array. So,\\n[quick sort](https://en.wikipedia.org/wiki/Quicksort) is a very good algorithm\\nfor this. It does not require extra memory space but only swapping elements\\nwithin the array.\\n\\nThe sort function has a default compare function, that is based on the Unicode\\norder of the string. So `7` comes before `80`, but `80` actually comes before\\n`9` by default. This is because when numbers are converted to string, the\\nUnicode of `\\"80\\"` is earlier than `\\"9\\"`. So, I first need to recreate this\\ndefault compare function in case the compare function is not specified.\\nFortunately, I can reuse the `String.localeCompare()` method.\\n\\nThen for sorting, I also used a helper function `doSort` for recursively sorting\\nthe array. It takes 4 arguments, the array to sort, the compare function, the\\nstarting index and the ending index of range within the array to sort.\\n\\n```js\\n  sort: <T>(array: Array<T>, compareFn?: (a: T, b: T) => number): Array<T> => {\\n    if (!compareFn) {\\n      compareFn = (a: T, b: T) => {\\n        const aStr = `${a}`;\\n        const bStr = `${b}`;\\n\\n        return aStr.localeCompare(bStr);\\n      };\\n    }\\n    doSort(array, compareFn, 0, array.length - 1);\\n    return array;\\n  },\\n```\\n\\nIf you want to know more about\\n[Quick sort](https://en.wikipedia.org/wiki/Quicksort), there are plenty\\nresources and examples on the Internet. The higher level idea is to pick a pivot\\nelement, then partition the current array in to two, with one partition\\ncontaining elements lower and the other partition contains elements higher than\\nthe pivot. Then recursively do the same algorithm for each of the two\\npartitions. The cool thing is this operation can be done without creating extra\\narrays, it is only swapping element around within the array, and keep tracking\\nthe indexes.\\n\\nI did not do much optimization, so this is certainly nowhere near the best\\nimplementation. The only thing I did is to pick a random pivot. This can lower\\nthe chance of the two partitions having a very different size. Partitions that\\nare not in similar size may lead to poorer performance because more comparison\\nand swapping are needed.\\n\\nBefore the algorithm starts, the pivot element is moved to the end of the range.\\nThen each of the element in the range is compared to this pivot element. If the\\ncompare function return a value smaller than 0, meaning the element is smaller\\nthan the pivot, we swap element at the pivot and the current element and\\nincrement the pivot index. This brings the current element to the earlier\\npartition. Once we finish looping the array, we swap the pivot element (at the\\nend of the range) with the pivot index to bring the pivot element in between the\\ntwo partitions. Then recursively do the same sort for the two partitions. You\\nmay find it easier to understand by watching animations or reading the code\\nbelow.\\n\\nThere are also one more tricky thing to handle, briefly mentioned above.\\nElements that are `undefined` or empty will not invoke the compare function.\\nThey are always sorted to the end of the array, where all `undefined` comes\\nfirst, then all empty element at the end. So the first four big `if` in the\\n`doSort` function is handling `undefined` and empty items. Only when neither of\\nthe element being compared nor the pivot element is `undefined` or empty, the\\ncompare function is invoked.\\n\\n```js\\nconst doSort = <T>(\\n  array: Array<T>,\\n  compareFn: (a: T, b: T) => number,\\n  startIndex: number,\\n  endIndex: number\\n) => {\\n  const length = endIndex - startIndex + 1;\\n  if (length <= 1) {\\n    return;\\n  }\\n\\n  const randomIndex = Math.floor(Math.random() * length) + startIndex;\\n  swap(array, randomIndex, endIndex);\\n\\n  let currentIndex = startIndex;\\n  let pivotIndex = startIndex;\\n  while (currentIndex < endIndex) {\\n    // pivot is empty, current in front, so swap\\n    if (!(endIndex in array)) {\\n      swap(array, currentIndex, pivotIndex);\\n      pivotIndex++;\\n      currentIndex++;\\n      continue;\\n    }\\n\\n    // current is empty but pivot is not, do nothing\\n    if (!(currentIndex in array)) {\\n      currentIndex++;\\n      continue;\\n    }\\n\\n    // pivot is undefined but current is defined, current in front, so swap\\n    if (array[endIndex] === undefined) {\\n      swap(array, currentIndex, pivotIndex);\\n      pivotIndex++;\\n      currentIndex++;\\n      continue;\\n    }\\n\\n    // current is undefined but pivot is not\\n    if (array[currentIndex] === undefined || array[endIndex] === undefined) {\\n      currentIndex++;\\n      continue;\\n    }\\n\\n    // neither are empty or undefined\\n    const compare = compareFn(array[currentIndex], array[endIndex]);\\n\\n    if (compare < 0) {\\n      swap(array, currentIndex, pivotIndex);\\n      pivotIndex++;\\n    }\\n\\n    currentIndex++;\\n  }\\n\\n  swap(array, pivotIndex, endIndex);\\n\\n  doSort(array, compareFn, startIndex, pivotIndex - 1);\\n  doSort(array, compareFn, pivotIndex + 1, endIndex);\\n};\\n```\\n\\nAnd the `swap` function is also a helper function I created to swap two elements\\nin the array. It has special cases to handle swapping empty items. This `swap`\\nfunction is also used in `.reverse()` to reverse the array by swapping elements\\nsymmetrically.\\n\\n```js\\nconst swap = <T>(array: Array<T>, i: number, j: number) => {\\n  if (i === j) {\\n    return;\\n  }\\n\\n  const firstTemp = array[i];\\n  const isFirstInArray = i in array;\\n  const isSecondInArray = j in array;\\n\\n  if (isSecondInArray) {\\n    array[i] = array[j];\\n  } else {\\n    delete array[i];\\n  }\\n\\n  if (isFirstInArray) {\\n    array[j] = firstTemp;\\n  } else {\\n    delete array[j];\\n  }\\n\\n  return array;\\n};\\n```\\n\\nFor the rest, you can check\\n[the repository](https://github.com/ethanppl/js-array) for the implementation.\\nRest of them are mostly simple copying and modifying the length of the array, or\\nsome variations of the above. The most complicated one would be `.splice()`\\nwhich requires some more thought into copying what are added and deleted and\\nmoving the items around in the array.\\n\\nJust a disclaimer, this is just a fun challenge I set for myself. I am not\\nconfident that the implementation is absolutely correct, and I am sure you could\\nfind improvements in both time and memory complexity if you wanted to.\\n\\n## Final thoughts\\n\\nDespite this exercise being a bit tedious. I think it is worth the effort.\\nEspecially with more AI tools and auto-completion, getting to know the\\nfundamentals of a language is important. I do not ever think sparse array will\\nbe useful, but knowing that it exists and why it exists is helpful.\\n\\nBuilding something from scratch, without the help of AI autocompletion, feels\\nlike it retrained my brain in designing algorithms and debugging logic errors.\\nIt brings me back to the time when I first learn about programming, when\\n[off by 1 error](https://en.wikipedia.org/wiki/Off-by-one_error) and\\n[infinite loop](https://en.wikipedia.org/wiki/Infinite_loop) is the most\\nfrequent mistake I make. I enjoyed the iterative process of running and testing\\nmy code to validate the algorithms.\\n\\nPeople often say how unreasonable and poorly designed the JavaScript language\\nis, which I agree. JavaScript\'s language design contains inconsistencies, for\\nexample, all the edge cases around empty slots and sparse arrays.\\nInconsistencies cause surprises, which means code are harder to reason about,\\nharder to maintain and debug. However, to me, this exercise provided an\\nopportunity for me to experience the inconsistencies. I am not reading about it\\nfrom forums or memes. I actually experienced it and I vividly remember how they\\nare handled. That is a rewarding thing out of all the tedious `in` checks.\\n\\nOther than the inconsistencies, I notice one major theme in JavaScript is the\\nlanguage assume the user is correct and avoid throwing errors. Throughout all\\nimplementations, there are only 2 cases where it will throw an error. First is\\nwhen `.reduce()` or `.reduceRight()` is called with an empty array plus no\\ninitial value given, a `TypeError` is thrown because nothing can be reduced or\\nreturned. The second is when `.with()` is called with an index that is not\\nwithin the `-array.length` to the `array.length` range, a `RangeError` is\\nthrown. I think the `.with()` function throwing for `RangeError` is a better\\ndesign choice compare to other functions that tries to mask the error and just\\nreturn a default like an empty array or `undefined`. If something is unexpected,\\nlike accessing items outside the range of indexes, clearly the user made a\\nmistake. In my opinion, throwing an error is better than letting the program\\ncontinues with hard coded default values. I understand the flexibility and\\npotential gain in user experience when used in client side applications, but\\nthat is just masking the problem and kicking the can down the road.\\n\\nI hope you learned something new about JavaScript array by reading this. And\\nmaybe this inspires you to try something out even if it seems trivial. You might\\nlearn something new on the way!\\n\\n## References\\n\\n### Docs\\n\\n- [MDN Docs on Array](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array)\\n- [TC39 Specs on the Array Prototype Object](https://tc39.es/ecma262/multipage/indexed-collections.html#sec-properties-of-the-array-prototype-object)\\n\\n### Time complexity of all Array functions\\n\\n_Maybe this is useful in the future, while I still remembers_\\n\\n- `n` denote the length of the original array\\n- `k` usually denote the input array length\\n\\n| Functions      | Time Complexity                                          |\\n| -------------- | -------------------------------------------------------- |\\n| at             | `O(1)`                                                   |\\n| concat         | `O(n)` where n being the length of the second array      |\\n| copyWithin     | `O(n)` or less where n being the number of items to copy |\\n| entries        | `O(1)` where each iteration is `O(1)`                    |\\n| every          | `O(n)` or less                                           |\\n| fill           | `O(n)` or less                                           |\\n| filter         | `O(n)` if callback is `O(1)`                             |\\n| find           | `O(n)` if callback is `O(1)`                             |\\n| findIndex      | `O(n)` if callback is `O(1)`                             |\\n| findLast       | `O(n)` if callback is `O(1)`                             |\\n| findLastIndex  | `O(n)` if callback is `O(1)`                             |\\n| flat           | `O(n ^ d)` in the worst case where d is the depth        |\\n| flatMap        | `O(n)` if callback is `O(1)`                             |\\n| forEach        | `O(n)` if callback is `O(1)`                             |\\n| includes       | `O(n)` or less                                           |\\n| indexOf        | `O(n)` or less                                           |\\n| join           | `O(n)`                                                   |\\n| keys           | `O(1)` where each iteration is `O(1)`                    |\\n| lastIndexOf    | `O(n)` or less                                           |\\n| map            | `O(n)` if callback is `O(1)`                             |\\n| pop            | `O(1)`                                                   |\\n| push           | `O(k)`                                                   |\\n| reduce         | `O(n)` if callback is `O(1)`                             |\\n| reduceRight    | `O(n)` if callback is `O(1)`                             |\\n| reverse        | `O(n)`                                                   |\\n| shift          | `O(n)`                                                   |\\n| slice          | `O(n)` or less                                           |\\n| some           | `O(n)` or less                                           |\\n| sort           | `O(n log n)` on average                                  |\\n| splice         | `O(n + k)` or less                                       |\\n| toLocaleString | `O(n)`                                                   |\\n| toReversed     | `O(n)`                                                   |\\n| toSorted       | `O(n log n)`                                             |\\n| toSpliced      | `O(n + k)`                                               |\\n| toString       | `O(n)`                                                   |\\n| unshift        | `O(n + k)`                                               |\\n| values         | `O(1)` where each iteration is `O(1)`                    |\\n| with           | `O(1)`                                                   |\\n\\n- For `flat`, that is just the absolute worse case scenario where n is the\\n  average length of every array exists, while each array contains n number of\\n  arrays within, like an exponential tree\\n- `push`, `splice`, `toSpliced` and `unshift` depend on the input size `k` of\\n  the elements to be added to the array\\n- For `toLocaleString` and `toString`, I am not sure, but I assume the same as\\n  `join` where it accesses each element and concatenate to a string, so O(n)"},{"id":"/2024/12/28/mfa-totp","metadata":{"permalink":"/blog/2024/12/28/mfa-totp","source":"@site/blog/2024-12-28-mfa-totp.md","title":"How does the 6 digits number in multifactor authentication works?","description":"What is that 6 digits number in the authenticator app? Why those numbers change","date":"2024-12-28T00:00:00.000Z","tags":[{"inline":true,"label":"Auth","permalink":"/blog/tags/auth"},{"inline":true,"label":"Computers","permalink":"/blog/tags/computers"}],"readingTime":15.75,"hasTruncateMarker":true,"authors":[{"name":"Ethan Pang","url":"https://ethanppl.com/","imageURL":"https://github.com/ethanppl.png","key":"ethan","page":null}],"frontMatter":{"title":"How does the 6 digits number in multifactor authentication works?","tags":[{"label":"Auth","permalink":"auth"},{"label":"Computers","permalink":"computers"}],"toc_min_heading_level":2,"toc_max_heading_level":3,"authors":"ethan","image":"./assets/mfa-totp/mfa-totp-app.webp"},"unlisted":false,"prevItem":{"title":"Reimplement all JavaScript Array Functions with while loops only","permalink":"/blog/2025/02/23/js-array"},"nextItem":{"title":"How I use keyd to remap my keyboard in Ubuntu 22.04 with Wayland","permalink":"/blog/2024/09/08/keyd"}},"content":"What is that 6 digits number in the authenticator app? Why those numbers change\\nevery 30 seconds? How are they generated? How does the server know that this is\\nthe correct number? How does it work offline?\\n\\nAlso, why do we need to scan a QR code when setting it up? What does the QR code\\ncontains? How secure is the whole system? What are the limitations? What to\\nconsider if implementing a server to support this authentication method?\\n\\nWe will start with a some simple intuitive explanation and slowly go into the\\ntechnical details and algorithms. Hopefully you can answer all the above\\nquestions after reading this. This is not a high level explanation of why it\'s\\ngood to have MFA, or how to deploy it, there are\\n[plenty](https://www.microsoft.com/en-us/security/blog/2020/01/15/how-to-implement-multi-factor-authentication/)\\n[of](https://www.cyber.gov.au/resources-business-and-government/maintaining-devices-and-systems/system-hardening-and-administration/system-hardening/implementing-multi-factor-authentication)\\n[resources](https://www.okta.com/resources/whitepaper/8-steps-for-effectively-deploying-mfa/)\\n[explaining](https://auth0.com/blog/multifactor-authentication-mfa/) that\\nalready. This article focus on the details of the technology under the hood.\\n\\n\x3c!-- truncate --\x3e\\n\\nIf you are ready, let\'s get started. First, we need to understand what is a\\nfactor means in multifactor authentication.\\n\\n## What is a \\"factor\\"?\\n\\nA factor is like a key for a different kind of locks. Imagine a door has only 1\\nlock, then everyone who has the key to that lock can open the door. Multifactor\\nis like having multiple locks on the doors that require different keys. Even if\\nyou lost 1 key accidentally, the door is still locked.\\n\\nIn digital systems, usually the lock is the username and password. If this is\\nthe only factor, if someone can steal or guess your password, then your account\\nis compromised. If there is an extra factor, usually in a different format, like\\nauthenticator app or a separate physical security key, then your account will be\\nsecure even if your password is leaked.\\n\\nIn [a study conducted by Microsoft in 2023](https://arxiv.org/abs/2305.00945),\\nMFA reduces the risk of being compromised by 99.22%! Also, dedicated\\nauthenticator app like Microsoft Authenticator outperform SMS-based\\nauthentication.\\n\\n## Time-based one-time password (TOTP)\\n\\nThis article will focus on explaining these authenticator apps, the one you see\\n6 digits number changing every 30 seconds. It is called time-based one-time\\npassword, TOTP in short. We will know how does the TOTP algorithm generate that\\n6 digits number, why does it change every 30 seconds, how does the server know\\nthe same 6 digits number even if the authenticator app is offline.\\n\\n![A typical authenticator app](./assets/mfa-totp/mfa-totp-app.webp)\\n\\nThe formal document that defines how TOTP should work is defined in\\n[RFC 6238](https://datatracker.ietf.org/doc/html/rfc6238). TOTP is a way to\\ngenerates a user-friendly value based on the current time, called the one time\\npassword (OTP), to authenticate the user. The one time password is used once\\nonly and cannot be reused. But before we go deep into the terminologies and how\\nall these work, let\'s look at a simpler, imaginative scenario to understand the\\nidea behind TOTP. Let\'s imagine we need to secure a phone call.\\n\\n## Explain like I am five\\n\\nImagine Alice and Bob phone call each other to share updates and secrets, but\\nthey are often scared that the phone is not picked up by one of them but\\nMallory, so they both come up with a secret phrase, \\"chipmunk\\" and \\"chinchilla\\".\\nEvery time before the phone call starts, Alice and Bob need to tell their secret\\nphrase. Only if both sides are correct, they start talking. It works well until\\none time Bob realize Mallory is listening from behind and hear the secret phrase\\n\\"chinchilla\\", what can they do?\\n\\n![Phone call with secret phrase](./assets/mfa-totp/phone.webp)\\n\\nTurns out, there is a special species of magic parrot. The magic parrots are\\nalways twin. At any given time, you can ask the magic parrot to say a random\\nword. The two magic parrots will say the same word even if they are physical\\nseparated far away.\\n\\n![Phone call secured by magic parrot twins](./assets/mfa-totp/phone-with-parrot.webp)\\n\\nNow, as long as Alice and Bob keep their magic parrot secure to them, they are\\nsafe. Even if Mallory knows the secret phrase \\"chipmunk\\" or \\"chinchilla\\", she\\ncannot impersonate Alice and Bob because she doesn\'t have that specific magic\\nparrot. She cannot reuse \\"goose\\" either because this word is randomly generated\\nby the magic parrot and used once only.\\n\\nIf you understand why the magic parrot makes it more secure, then you know why\\nTOTP makes authentication systems more secure. The magic parrot is the second\\nfactor. In TOTP, \\"chipmunk\\" or \\"chinchilla\\", is your username and password. And\\n\\"goose\\" is the TOTP, the generated one-time password. The magic parrot is the\\nTOTP algorithm. It can generate a random value at any given time.\\n\\nIn the real world, there is no magic parrot twins that work like this, but we\\ncan create something digitally that works in the same way.\\n\\n## TOTP in detail\\n\\nThis is the typical flow of an authentication with TOTP.\\n\\n![The typical flow of TOTP authentication](./assets/mfa-totp/totp-sequence.webp)\\n\\n1. The user first login with username and password, or any other authentication\\n   methods like\\n   [single signed-on (SSO)](https://en.wikipedia.org/wiki/Single_sign-on)\\n2. The server verifies the identity and confirm that the user has enabled\\n   multifactor authentication, so the server requests the user to provide the\\n   TOTP\\n3. The user get the TOTP from where it is stored, e.g. authenticator app or\\n   password managers, and submits it\\n4. The server also generates the TOTP from its end and compare the two is the\\n   same\\n\\nWe are going to focus on step 3 and 4, particularly how the user and the server\\nare able to generate the TOTP without communicating at that point.\\n\\nTo understand how TOTP is generated and why it is secure, we need to know three\\nbasic ingredients. A hash function, the Unix timestamp and a shared secret\\nbetween the server and the user.\\n\\n### Hash functions\\n\\n[Hash functions](https://en.wikipedia.org/wiki/Hash_function) in short are any\\none-way function that can map any data into another fixed size value. It has a\\nfew key properties that you need to keep in mind:\\n\\n1. Given the same data, it will always generate the same hash\\n2. Given a different set of data, it will always generate a different hash\\n3. When given a hash, it\u2019s impossible to guess or know what is the data that\\n   generated this hash\\n\\nBased on the first two properties, hash functions should never collide. The\\nnumber of bits in a hash is large, usually 256 or above. At that scale, a\\ncollision is extremely unlikely. If you don\'t believe this work you may watch\\n[this video from 3blue1brown on how secure is 256 bits](https://youtu.be/S9JGmA5_unY)\\nor read about the\\n[birthday problem](https://en.wikipedia.org/wiki/Birthday_problem).\\n\\nHash functions should also be one-way. One intuitive way to understand one-way\\nfunction is multiplication and factoring. Multiplying two numbers together is\\nkind of like \\"one-way\\". It is relatively easy to calculate 89 \xd7 67 = 5963, I\\nbelieve you can do it with a pen and paper in a minute. But if only 5963 is\\ngiven, and you were asked to find out which two numbers multiply to 5963, it\'s\\nway harder. Hope this can convince you there are such one-way, irreversible\\nmathematical operations exist. They aren\'t absolutely impossible to reverse,\\njust way harder.\\n\\n### Unix time\\n\\nThe second basics we need to understand is there is a globally universal\\ntimestamp. Even though your computer might be disconnected from the internet, as\\nlong as it has battery and the clock is correct, all computers should share the\\nsame timestamp.\\n\\nIn computers, there is a standard way to define the time, which is the\\n[Unix time](https://en.wikipedia.org/wiki/Unix_time). That is the number of\\nseconds since 00:00:00 UTC on 1 January 1970. There are some quirks and\\nexceptions (e.g. leap seconds), but all computers should be able to calculate\\nthe same Unix time at any given moment.\\n\\nThe timestamp is the important let the server and user generates the TOTP code\\nseparately without communication to each other.\\n\\n### Shared secret\\n\\nThe last but not least is there is a shared secret only know by the server and\\nthe user. When you use the authenticator app to scan a QR code to register the\\nmultifactor authentication, that is when the shared secret is exchanged.\\n\\nThe shared secret should not be revealed after the initial exchange. The shared\\nsecret should be random, unique for each user, and has a high\\n[entropy](<https://en.wikipedia.org/wiki/Entropy_(information_theory)>) that\\nit\'s not possible to be guessed or brute forced.\\n\\nIn the authenticator app example, the authenticator app gets the shared secret\\nfrom the QR code and stores it, which usually is just random bytes of human\\nunreadable data. The server also stores a copy of the secret uniquely linked to\\nthis user.\\n\\nNow we go to the actual algorithm.\\n\\n### TOTP algorithm\\n\\nThe TOTP algorithm works like this:\\n\\n1. Using a hash functions to hash the shared secret recursively\\n2. Using the current timestamp to determine how many times to hash\\n3. Calculate the modulus of the hash based on the size of the TOTP, this gives a\\n   human-readable 6 digits number\\n\\nYou can read more of the detail algorithm in\\n[section 4](https://datatracker.ietf.org/doc/html/rfc6238#section-4) of the RFC,\\nwhich is based on top of the HMAC-based One-Time Password (HOTP) algorithm\\ndefined in [RFC 4226](https://datatracker.ietf.org/doc/html/rfc4226).\\n\\nThe hash function used as specified in the RFC 6238 should be\\n[SHA-256 or SHA-512](https://en.wikipedia.org/wiki/Secure_Hash_Algorithms). This\\nis also agreed and stored in the authenticator app when scanning the QR code.\\nBecause hash functions generate different value given different input, without\\nknowing the shared secret, it is impossible to generate the same number. This is\\nthe reason why at any given time, there is only 1 valid number for this user,\\nand the server is able to verify that. Also, because hash functions are one-way,\\neven if the TOTP code is exposed, it is not possible to guess the shared secret\\nunless brute force.\\n\\nIn this algorithm, the timestamp used is not the exact Unix time, otherwise the\\n6 digits number will change every second. It will be impractical to ask a user\\nto enter 6 digits and submit within a second. The longer the time before\\nchanging the number, the better the usability for the users, because it\'s less\\nlikely the number changed midway when the user is inputting it. But the longer\\nit is, the less secure it is, because there is a larger window that the TOTP is\\nexposed. It\'s always a trade-off. The RFC 6238 recommends a time step of 30\\nseconds, which means the number only change every 30 seconds. If you open your\\nauthenticator app now, and reference a clock, you should see the number\\nrefreshes at the 00 or 30 seconds mark in a minute, unless it is not using 30\\nseconds as the time step.\\n\\nAs you can see, even if the authenticator app is offline and there is no\\ncommunication between your phone and the server, both of them can generate the\\nsame 6 digits number.\\n\\n### Resynchronization\\n\\nIt is possible that there are delays in the network connection, or the clock on\\nthe user device is delayed, or the user input the number too slow. As such, the\\nRFC recommends the validation server support resynchronization. For example, the\\ncurrent and the last 2 TOTP generated are all valid. The number of steps\\nbackward to consider valid is again a trade-off between usability and security.\\nThe server may optionally record the drift that the user clock has and adjust\\nfor that in future validations.\\n\\n## Security Considerations\\n\\nThere are various best practices for TOTP to be secure.\\n\\nFirst, the user must keep their TOTP secret a secret. It is assumed that the\\nsecret is securely stored in authenticator app or password manager. That should\\nnot be accessible over the internet. Therefore,\\n[it is controversial](https://news.ycombinator.com/item?id=35708869) when Google\\nAuthenticator supports syncing and backing up secrets to Google.\\n\\nAll communications between the user and the server should be done over a secure\\nchannel, e.g. HTTPS. It is true that revealing the TOTP will not leak the shared\\nsecret, but it\'s best to not leak it at all. The initialization phase must be\\ncommunicated over secure channel. If the initial setup QR code is leaked, the\\nattacker has access to the shared secret and the attacker can always generate\\nthe TOTP.\\n\\nThe TOTP code should also be used once only, as specified in the name, one-time\\npassword. For example, if the user login to the account using a TOTP code, that\\ncode should not be valid any more. This is to prevent an attacker that has\\naccess to the newly sent TOTP code from reusing that code to gain access. The\\nuser must wait for 30 seconds for the next code to be generated to log in.\\n\\nGiven all these practices, the best possible attack against this system should\\njust be brute forcing to guess the shared secret. And as mentioned, the shared\\nsecret should be long enough that it\'s not possible to guess and brute force in\\nreasonable timeframe.\\n\\nTOTP is still vulnerable to phishing attacks. Say the user is logging into a\\nfake authentication website, or willing transferring the generated TOTP to\\nattackers. Attackers can then proxy or input the TOTP code in real time to gain\\naccess to the system.\\n\\n## Implementation Details\\n\\nThere are two things to set up for the server. Initializing the TOTP and\\nauthentication the TOTP.\\n\\n### Setting up TOTP\\n\\nWhen a user set up TOTP, the server usually provides a QR code. It is the\\neasiest way and foolproof way to exchange the shared secret. The user can use a\\nseparate device to get the secret without the need to copy and paste. Most\\nphones have a camera nowadays, and password manager browser extensions (e.g.\\n[1Password](https://support.1password.com/one-time-passwords/)) can scan QR\\ncodes as well. QR codes have error correction by default and since users do not\\nneed to type in the unreadable secret, making it less likely to make mistakes.\\n\\nThe QR code is usually a URL in the format of\\n\\n```\\notpauth://totp/<issuer>:<account>?secret=<RandomBytesOfData>\\n```\\n\\n- `otpauth` is the scheme\\n- `totp` is the type of OTP that we are using\\n- The issuer is usually the organization, e.g. Google, Microsoft\\n- The account is usually your username or email\\n- The secret must be present in the parameters, usually a long string\\n- There are optional parameters like `algorithm` for the hash function used,\\n  `period` which defaults to 30 as mentioned above, and `digits` for the number\\n  of digits in the OTP code, which is usually 6\\n- You can read more about the URL format of TOTP in\\n  [this page](https://docs.yubico.com/yesdk/users-manual/application-oath/uri-string-format.html)\\n\\nBefore the user account has MFA enabled, the server should ask for a TOTP code\\nto verify that the user correctly saved the shared secret. Only if that code is\\nvalid, MFA is successfully enabled. The server needs to handle the state where\\nthe shared secret is generated and stored, but the MFA is not enabled yet.\\n\\n### Recovery Codes\\n\\nIn practical use, it is possible that users lose access to their phone or\\nwherever the TOTP codes are generated. It is a challenging aspect because the\\neasier it is for a user to recover the account after failed to log in with MFA\\nmeans the easier it is for attacker to use the same method to compromise the\\naccount.\\n\\nOne way to recover the account is the server provides some single-use recovery\\ncodes, usually some longer random strings. They are usually shown to the user\\nonce after the MFA is first successfully enabled. Each recovery codes should\\nonly be used once only, same as how TOTP codes can only be used once to prevent\\nreplay by an attacker.\\n\\nDuring authentication, the system should allow the user to input recovery codes\\nand if matches, the user is logged in but that recovery code is invalidated. The\\nusers are responsible for keeping the recovery codes secure and use it only when\\nTOTP codes are not available.\\n\\nAlternative recovery methods includes\\n\\n- Mailing a one-use recovery codes to the user\\n- Require the user to contacting the support team to verify the identity before\\n  resetting the MFA\\n- Require users to set up multiple MFA to limit the likelihood of losing access\\n  to all methods at once\\n\\n### Authenticating TOTP\\n\\nBefore supporting MFA, the login endpoint of the server will either return login\\nsuccess or login failed. With TOTP supported, the server has a third response,\\nindicating the credentials are valid but a TOTP code is required because MFA is\\nenabled.\\n\\nIn this response, the server should also return a unique token, (e.g. a JWT\\ntoken) to the frontend. This token will expire in a short period of time, like 5\\nminutes. It has to be submitted to a separate TOTP validation endpoint together\\nto signal that this particular user already passed the username & password\\nvalidation in a previous step. The server use this token to determine which user\\nis trying to log in and which TOTP shared secret to use to validate the TOTP\\ncode submitted. Without this step, a user can just log in with a TOTP code in\\nthe TOTP endpoint without even having the password validation step, which means\\nthe system is back to single factor authentication. Another option is the\\nfrontend stores the previously inputted username and password, and submit that\\nto the server alongside the TOTP code.\\n\\n### Libraries and third party service\\n\\nKnowing how the algorithm works behind the scenes is great, but you should never\\nimplement the algorithms yourself. Use a library instead. For example,\\n[`otpauth`](https://www.npmjs.com/package/otpauth) in the NPM registry for Node,\\nDeno, Bun runtime in JavaScript.\\n\\nThere are also third party services that provide authentication or MFA as a\\nservice. It is good for applications that do not have resources to implement\\ntheir own authentication system, but also require careful consideration for the\\nsecurity, integrity and availability of the third party service.\\n\\n## Useful links\\n\\n- [OWASP Multifactor Authentication Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Multifactor_Authentication_Cheat_Sheet.html)\\n- [RFC 6238 TOTP: Time-Based One-Time Password Algorithm](https://datatracker.ietf.org/doc/html/rfc6238)\\n- [Wikipedia: Multi-factor Authentication](https://en.wikipedia.org/wiki/Multi-factor_authentication)\\n- [Wikipedia: Time-based One-time Password](https://en.wikipedia.org/wiki/Time-based_one-time_password)"},{"id":"/2024/09/08/keyd","metadata":{"permalink":"/blog/2024/09/08/keyd","source":"@site/blog/2024-09-08-keyd.md","title":"How I use keyd to remap my keyboard in Ubuntu 22.04 with Wayland","description":"Think about how you use your keyboard. Imagine how good it would be if your","date":"2024-09-08T00:00:00.000Z","tags":[{"inline":true,"label":"Ubuntu","permalink":"/blog/tags/ubuntu"},{"inline":true,"label":"Tips & Configs","permalink":"/blog/tags/tips-and-configs"},{"inline":true,"label":"Computers","permalink":"/blog/tags/computers"}],"readingTime":12.77,"hasTruncateMarker":true,"authors":[{"name":"Ethan Pang","url":"https://ethanppl.com/","imageURL":"https://github.com/ethanppl.png","key":"ethan","page":null}],"frontMatter":{"title":"How I use keyd to remap my keyboard in Ubuntu 22.04 with Wayland","tags":[{"label":"Ubuntu","permalink":"ubuntu"},{"label":"Tips & Configs","permalink":"tips-and-configs"},{"label":"Computers","permalink":"computers"}],"toc_min_heading_level":2,"toc_max_heading_level":3,"authors":"ethan"},"unlisted":false,"prevItem":{"title":"How does the 6 digits number in multifactor authentication works?","permalink":"/blog/2024/12/28/mfa-totp"},"nextItem":{"title":"Don\'t say it\'s a weird bug, because it makes you look stupid","permalink":"/blog/2024/06/19/weird-issue"}},"content":"Think about how you use your keyboard. Imagine how good it would be if your\\n`CapsLock` can be used as `Ctrl`, how much better it would be for your left\\npinky? That is the power of remapping the keyboard. It means you can customize\\nthe functionality of each key on your keyboard.\\n\\nThis is a walkthrough of my setup in Ubuntu using `keyd`. A guide I wish it\\nexisted when I first try to find out how to remap my keyboard in Ubuntu.\\n\\n\x3c!-- truncate --\x3e\\n\\n![xkcd 1806](https://imgs.xkcd.com/comics/borrow_your_laptop.png)\\n\\n_[xkcd 1806: borrow your laptop](https://xkcd.com/1806/)_\\n\\n## Why I Remap my Keyboard\\n\\nAfter I [dual-boot with Ubuntu](./2024-02-29-dual-boot-guide.md) and used it as\\nmy daily driver for work and personal use, one key thing I missed is\\n[AutoHotkey](https://www.autohotkey.com/). It is a software that I used to remap\\nmy keyboard in Windows and create shortcuts and \\"hotstrings\\". For example,\\n\\n- Remapping `CapsLock` to `Ctrl` on hold, but works as `Esc` when clicked alone\\n- `z+d` to scroll down and `z+u` to scroll up, and other ways to move my mouse\\n- `z+e` and `z+g` to insert my email addresses\\n- `|!=`, `|->`, `|<-` will be replaced by not equal (\u2260), right arrow (\u2192) and\\n  left arrow (\u2190), etc., automatically\\n\\nI shared\\n[my AHK configuration in this repository](https://github.com/ethanppl/ahk) if\\nyou are interested. I might write about it later too.\\n\\nI think remapping keyboard is one of the most important change I made to my\\nlaptop ever since I know how to use a computer. It is like the first time you\\ndiscovered you can use `Ctrl+C` rather than right click and select copy. I\\nhighly encourage everyone to try it, especially for keys like `CapsLock` that is\\nin a very convenient location but is rarely used.\\n\\nSo once I boot to Ubuntu, the first thing I wanted to do is to replicate this\\nsetup. Unfortunately, AHK only works for Windows, so I need to look for\\nalternatives. The first difficulty that you might face as well is Ubuntu 22.04\\nby default uses [Wayland](<https://en.wikipedia.org/wiki/Wayland_(protocol)>) as\\nthe window system, but a lot of tools available online works for\\n[X11](https://en.wikipedia.org/wiki/X_Window_System) only. For example, there is\\n[AutoKey](https://github.com/autokey/autokey) that seems to be popular but only\\nworks for X11.\\n\\nI first tried [`input-remapper`](https://github.com/sezanzeb/input-remapper). It\\nlooks promising with nice graphical user interface, but it didn\'t work out when\\nI tried to add more complicated logics. I also tried\\n[keyboard](https://github.com/boppreh/keyboard), a Python module which allows me\\nto create custom keyboard events in Python code. It\'s like coding my own daemon,\\nbut I found it too much overhead and quite laggy. In the end, I found\\n[a list of input remapping utilities](https://wiki.archlinux.org/title/Input_remap_utilities)\\nprovided by Arch Linux wiki. Going through the list and I chose\\n[`keyd`](https://github.com/rvaiya/keyd) which works for me quite well over the\\npast year.\\n\\nIf you are using Windows, you can check\\n[AutoHotkey](https://www.autohotkey.com/) as linked above. If you are on Mac, I\\nread that\\n[Karabiner](https://karabiner-elements.pqrs.org/docs/getting-started/features/)\\nis good, but I have not used a Mac before. If your keyboard supports it,\\n[QMK](https://docs.qmk.fm/#/newbs)/[VIA](https://www.caniusevia.com/docs/specification)\\nmight be good for you. Even if `keyd` doesn\'t work for you, you may follow along\\nto get some inspiration even though the syntax of the config is not the same.\\n\\n## Basic Concepts in `keyd`\\n\\nThe very first thing to understand in `keyd` config is it operates in terms of\\nlayers. The most intuitive way for me to understand a layer is the `Shift` key.\\nWhen the `Shift` key is pressed and hold, a different layer is activated and all\\nthe keys on your keyboard have a different meaning. And what `keyd` allows you\\nto do is to define custom layers, that is, defining how the layers are activated\\nand deactivated, and what each key means in each of the defined layer.\\n\\nThe major reason I select `keyd` is it works in X, sway and gnome in Wayland.\\nSecond, it natively supports key overloading, which allows me to configure the\\n`CapsLock` key to behave as `Ctrl` on hold while `Esc` when tapped. From what I\\ntest, it is instant and fast too.\\n\\nTo get started, install `keyd` from source. Clone\\n[the repository](https://github.com/rvaiya/keyd) and build it from source.\\nFollow the instructions in the\\n[README](https://github.com/rvaiya/keyd?tab=readme-ov-file#from-source) to\\ninstall it.\\n\\nHere are some helpful commands to know:\\n\\n- `sudo systemctl enable keyd`: start `keyd`, probably run it once in your\\n  lifetime\\n- `sudo keyd reload`: reload the config every time after you edit the config\\n- `sudo keyd monitor`: print key events, useful to debug what is remapped\\n- `keyd list-keys`: list all the valid key names, useful to check the\\n  possibilities\\n- `backspace+escape+enter` keyboard combo: terminate `keyd` anywhere anytime in\\n  case you severely messed up (happened once to me)\\n\\n## Sharing my Configuration\\n\\nHere is the full config if you are interested. I will explain it line by line\\nbelow.\\n\\n```\\n[ids]\\n\\n*\\n\\n[main]\\n\\n# Maps capslock to escape when pressed and control when held.\\ncapslock = overload(control, esc)\\n\\n# Maps z to a custom layer, but just \'z\' when pressed.\\nz = overload(z, z)\\n\\n# Shift layer\\n[shift:S]\\n\\n## shift+capslock is capslock\\ncapslock = capslock\\n\\n# Custom z layer\\n[z]\\n\\n## Escape common patterns\\ni = macro(zi)\\no = macro(zo)\\n\\n## Emails\\ne = macro(hi@ethanppl.com)\\ng = macro(hi@ethanppl.com)\\n\\n## Simplify complicated shortcut keys\\nv = C-S-v\\nn = C-S-a\\nx = A-f4\\ns = command(systemctl suspend)\\n\\n## Arrows\\nj = down\\nk = up\\nh = left\\nl = right\\n\\n## Media / modifier\\nm = oneshot(media)\\n\\n[media]\\n\\nj = previoussong\\nk = playpause\\nl = nextsong\\n\\na = macro({ enter 10ms \\"Aut 10ms hor 10ms iza 10ms tio 10ms n\\": space \\"Bea 10ms rer space C-v)\\n\\n```\\n\\n### Main layer\\n\\nLet\'s go through it line by line.\\n\\n```\\ncapslock = overload(control, esc)\\n```\\n\\nThis is the most important feature that I need, as introduced in the beginning.\\nAccording to the man page, `overload(<layer>, <action>)` \\"activates the layer on\\nhold while executes the action on tap\\". This line means `CapsLock` will act like\\n`Ctrl` when used with other keys. But when I tap it only, it works as `Esc`.\\nThis makes key combo like `Ctrl+C` way easier than before, where the `Ctrl` key\\nis in the bottom left. It also makes `Esc` easier, which is used a lot in Vim.\\nThis single line is the biggest reason why I picked `keyd`.\\n\\n```\\nz = overload(z, z)\\n```\\n\\nThis might seem weird when you first look at it, but think about the key `z` as\\nits own layer (remember, layer is like the `Shift` key). So when `z` is hold, it\\nactivates a `z` layer, like holding the `Shift` key activate the shift layer,\\nbut it acts as `z` when tap alone. This gives me another modifier key (e.g.\\n`Ctrl`, `Alt`, `Shift`), without overriding what the default keyboard shortcuts\\nthat come with software programs. But before we go into this special `z` layer,\\nwe need to fix one thing first.\\n\\n### Shift layer\\n\\n```\\n[shift:S]\\n\\ncapslock = capslock\\n```\\n\\nWe don\'t have a `CapsLock` key after we remap it. What this two lines do is\\nthat, in the shift layer, map `CapsLock` to work as `CapsLock`. So to summarize,\\nright now holding `CapsLock` is `Ctrl`, tapping `CapsLock` once is `Esc`, and\\ndoing `Shift+CapsLock` is `CapsLock`.\\n\\n### The `z` layer\\n\\n```\\ni = macro(zi)\\no = macro(zo)\\n```\\n\\nFirst thing is since I did this custom `z` layer with AutoHotkey in Windows, I\\nrealized the character `i` and `o` commonly follows the `z` key (e.g. amazing\\nand amazon). To avoid delay in typing or keys being ignored because I typed `i`\\nbefore releasing `z`. I mapped press and hold `z` then `i` (`z+i`) to output\\n`zi` and `z+o` to output `zo` here.\\n\\nI use `+` sign to mean press and hold the first key and type the second key. But\\n`keyd` use `+` sign to mean chording, which means two keys to be pressed at the\\nsame time. I didn\'t use chording in my config and most of the documentation for\\nkeyboard shortcuts often use `+` sign like `Ctrl+c`, so I hope it\'s easy to\\nunderstand.\\n\\n```\\ne = macro(hi@ethanppl.com)\\ng = macro(hi@ethanppl.com)\\n```\\n\\nNext, I mapped `z+e` and `z+g` to two emails that I used the most for\\ncommunication and sign in. You will be amazed how many times you type your email\\neach day. And how much better you don\'t need to type `@` anymore.\\n\\n```\\nv = C-S-v\\nn = C-S-a\\nx = A-f4\\ns = command(systemctl suspend)\\n```\\n\\nHere I simplified some commonly used shortcuts with the `z` layer. In `keyd`,\\ncapitalized `C`, `S` and `A` means `Ctrl`, `Shift` and `Alt` key respectively.\\nAnd the hyphen `-` means press and hold. For example, `z+v` is an alias of\\n`Ctrl+Shift+V` which is often used as paste text only or the markdown preview in\\nVSCode. `z+n` is an alias of `Ctrl+Shift+a` which shows information of all tabs\\nin Chrome. `z+x` is an alias of `Alt-F4` which closes a window. And `z+s` run\\nthe `systemctl suspend` command, which will suspend the laptop. I find this\\nhelpful, and somehow I trust it to suspend my laptop successfully more than just\\nclosing the lid of my laptop.\\n\\n```\\nj = down\\nk = up\\nh = left\\nl = right\\n```\\n\\nHere I mapped `j`, `k`, `h`, `l` to be arrow keys. For example, holding `z+l`\\nwill produce the right arrow key. The reason for these mappings (e.g. why `j` is\\ndown) are based on Vim motions. These are helpful because arrows are usually\\nunreachable unless I move my palm away from my keyboard. Doing `z+l` allows me\\nto do things like autocomplete in terminal without moving my palm.\\n\\nYou might also notice that I try to pair keys that are comfortable to reach when\\nholding `z` down, like I would avoid mapping anything to `z+a` that is just\\ncomplicated and unnatural to type.\\n\\n### The `z+m` layer, a layer on top of a layer\\n\\n```\\nm = oneshot(media)\\n```\\n\\nStill in the `z` layer, I defined the `m` key to activate the `media` layer. It\\nactivates this layer as `oneshot`. The man page defined `oneshot` as \\"If tapped,\\nactivate the supplied layer for the duration of the next key press\\". It means\\nthe layer is activated once tapped, and it will be toggled off only after\\nanother key is pressed. This means the `media` layer is activated once we tap\\n`z+m`, and we don\'t have to hold it for it to be active (unlike the `shift` or\\n`z` layer).\\n\\n```\\n[media]\\n\\nj = previoussong\\nk = playpause\\nl = nextsong\\n```\\n\\nI discovered these keys when browsing through the `keyd list-keys` command. And\\nUbuntu support these keys. How this works is once I pressed `z+m`, then tap `l`,\\nit will emit a `nextsong` key press. What this allows me to do is whichever\\nactive window I am in, I can use `z+m`, then `j`, `k`, or `l` to go back, pause,\\nor skip a song in Spotify, which I think is pretty amazing.\\n\\n```\\na = macro({ enter 10ms \\"Aut 10ms hor 10ms iza 10ms tio 10ms n\\": space \\"Bea 10ms rer space C-v)\\n```\\n\\nOne last line which doesn\'t relate to media actually, but I put it in any way.\\nIt is used to help me type the authorization header in GraphQL playground. What\\nI have to do is copy the token that I want to use, then type `z+m` and `a`, it\\nwill help me generate the whole\\n\\n```\\n{\\n  \\"Authorization\\": \\"Bearer <token_copied_here>\\"\\n}\\n```\\n\\nIt is taking advantage of the GraphQL playground I used that will help me close\\nthe `{` curly braces. With some trial and error I realize I cannot make `keyd`\\nto type all keys at once, so I leave some delay in between and that works\\nbetter. Having it run `Ctrl+V` to paste also helps a lot. I find this saves me\\nquite some time each day.\\n\\n## Other thoughts\\n\\nThere are many other features in `keyd` that is up to you to explore. I have\\nadded different configs in and out over the year until I settle down to this set\\nof commands. For example, initially I also configured a shortcut to type\\n`console.log` and `IO.inspect` for TypeScript and Elixir, other than the\\nauthorization header shortcut, but I found out I rarely used them and I removed\\nthem.\\n\\nI also tried `oneshot(shift)` which is recommended in the `keyd` README. But it\\ndidn\'t work for me. I find out I often tap `Shift` but changed my mind\\nafterwards, which makes me accidentally typed characters in uppercase. I also\\nfind out `oneshot(shift)` doesn\'t work well with Shift and drag to select in\\nbulk with mouse because it doesn\'t understand there is a mouse click and\\ndeactivate the shift layer after I realize the `Shift` key.\\n\\nAnother thing I found is the `command()` call doesn\'t always work. I once\\ninstalled `copyq` to get clipboard history and I configured `z+c` to be\\n`command(copyq show)`, but it never worked. It\'s not a dealbreaker and I didn\'t\\nspend time to debug why.\\n\\nOne thing you might already notice is there is no more hotstrings, which I had\\nin [my AutoHotkey configuration](https://github.com/ethanppl/ahk). I can no\\nlonger type `\u2260`, `\u2192`, `\u2190` and other special characters that easily. I realize\\nconfiguration like `l = \u2190` doesn\'t work. After reading the man page, I believe I\\ncan make it works by setting up Unicode support, which have some other external\\nconfiguration required, and I have not spent the time investigating.\\n\\nThere is also no more mouse control. There is no way to move my mouse with\\n`keyd` because all `keyd` does is to remap keys. I know there are other daemons\\nin Linux that are designed for that, but I have not tried. There are\\n[`warpd`](https://github.com/rvaiya/warpd) for X11, macOS, or Sway only, but not\\nWayland in gnome.\\n\\nThere are also some minor problems that I wish to solve in the future. For\\nexample, `Ctrl+<arrows>` is a common key combination that I do, but I can\'t\\neasily do that with `CapsLock+z+<hjkl>` because the relative position of\\n`CapsLock` and `z` is too close.\\n\\nI would like to try mapping specific shortcuts to specific applications too. But\\nmost of the time I find the default configs coming with the app works good\\nenough. Also, I did not configure any keys to launch an application because I\\nfind `meta+<num>` good enough to open the windows that are pinned to the task\\nbar. For example, `win+2` always open my browser and `win+3` open VSCode.\\n\\nThat is how my configuration in `keyd` works and some of my reasoning behind it.\\nI hope you like this explanation, and it inspires you to remap your keyboard\\ntoo. It genuinely improved my life.\\n\\n_You might be interested in [this page about keyboards](/computers/keyboard) in\\nmy Wiki too._\\n\\n## Useful links\\n\\n- [`keyd` repository](https://github.com/rvaiya/keyd)\\n- [`keyd` examples](https://github.com/rvaiya/keyd/tree/master/examples) by the\\n  creator\\n- If you are stuck, you might find a solution by searching the\\n  [issues in `keyd`](https://github.com/rvaiya/keyd/issues)"},{"id":"/2024/06/19/weird-issue","metadata":{"permalink":"/blog/2024/06/19/weird-issue","source":"@site/blog/2024-06-19-weird-issue.md","title":"Don\'t say it\'s a weird bug, because it makes you look stupid","description":"Often when someone is debugging an issue, you might hear:","date":"2024-06-19T00:00:00.000Z","tags":[{"inline":true,"label":"Thoughts","permalink":"/blog/tags/thoughts"},{"inline":true,"label":"Workplace","permalink":"/blog/tags/workplace"}],"readingTime":5.83,"hasTruncateMarker":true,"authors":[{"name":"Ethan Pang","url":"https://ethanppl.com/","imageURL":"https://github.com/ethanppl.png","key":"ethan","page":null}],"frontMatter":{"title":"Don\'t say it\'s a weird bug, because it makes you look stupid","tags":[{"label":"Thoughts","permalink":"thoughts"},{"label":"Workplace","permalink":"workplace"}],"toc_min_heading_level":2,"toc_max_heading_level":3,"authors":"ethan"},"unlisted":false,"prevItem":{"title":"How I use keyd to remap my keyboard in Ubuntu 22.04 with Wayland","permalink":"/blog/2024/09/08/keyd"},"nextItem":{"title":"Dual Boot Windows and Ubuntu with Secure Boot and Full Disk Encryption","permalink":"/blog/2024/02/29/dual-boot-guide"}},"content":"Often when someone is debugging an issue, you might hear:\\n\\n- It\'s a _weird bug_\\n- _Somehow_ it throws an error, it\'s _weird_\\n- I followed the README, but _weirdly_ it doesn\'t work\\n\\nAs if something outside their control misbehaved, they expect someone to help\\nthem eliminate the \\"weirdness\\". I find that a bit annoying. What does \\"weird\\"\\nactually mean?\\n\\nWe think \\"it\'s weird\\" because we feel like we did nothing wrong, and the outcome\\nis not what we intended. We do not understand why something unexpected happened,\\nand our first instinct is to label it as \\"it\'s weird\\". If the system is \\"weird\\",\\nthen it is no longer our problem.\\n\\nHowever, is this true? Should you ever say computers behaved \\"weirdly\\"?\\n\\n\x3c!-- truncate --\x3e\\n\\n## Computers never lie\\n\\nOne day, something like this happened. I was interrupted by my colleague because\\nhe found a weird issue. He was debugging an API. While testing it, he missed the\\nauthorization token in one of the service-to-service APIs, and as expected, an\\nunauthorized error was thrown. His immediate response was \\"weird\\", and then seek\\nhelp, and told me \\"it\'s weird\\". Huh? Why? What is weird though?\\n\\nI understand what he felt like \\"weird\\" is he supplied a user token already, how\\ncan it be unauthorized? The unauthorized error feels \\"weird\\" because the reason\\nis unknown. However, the reality is one of the APIs the program uses expects\\nanother type of token, and the code missed that. There is nothing \\"weird\\", but\\nthat immediate thought of the computer being \\"weird\\" makes it sound like he\\nthinks the computer lied to him, hence weird.\\n\\nBut computers don\'t lie! Computers are devices that take inputs, process and\\nthen output. If the output is unexpected, either the inputs or the process, or\\nboth are wrong. Data and code are both provided by users, programmers or other\\nsystems. The computer only executes it. There is nothing weird about the\\ncomputer itself.\\n\\nIt\'s even worse when a developer says something is weird with the program that\\nthey wrote. You wrote the program! The computer follows your instructions. How\\nwould you blame something that exactly follows your instructions as weird, and\\npretend to take no ownership of the error?\\n\\nIf you think seeing an unauthorized error is weird. It\'s not the computer\\nbehaving weirdly, instead, it is you not understanding how your code works. It\\nis you not checking the API documentation before commenting it is weird. It is\\nnot the computer lying to you therefore the code throw an error. Instead, it is\\nyou who made a mistake in the code causing it to throw.\\n\\nComputers don\'t lie. Even if they do because of hardware failure or cosmic rays\\nfrom light years away flipping a bit in the processor, it\'s abiding by the law\\nof physics. Figure out why and own the problem. That\'s how you learn.\\n\\n## Why it makes you look stupid\\n\\nWhen blaming something as weird, it sounds like blaming some external factors\\ncausing the weirdness, as if you take no responsibility for the issue, and you\\nare not eager to understand the problem.\\n\\nWhen you get used to saying \\"it\'s weird\\" to anything unexpected, your first\\ninstinct is to make it sound like you have no control. It sounds like you do not\\nunderstand the issue only because some \\"weirdness\\" is hindering your ability to\\nunderstand. But to someone who understands, they know the reason is you lack the\\nknowledge to understand, not because it\'s weird. It just sounds like you do not\\nunderstand how things work, you are making up excuses, and you are not taking\\nownership of figuring it out yourself. It doesn\'t matter how you think, it might\\njust be a filler word, but others who listen feel differently. It sounds like\\nyou are stupid.\\n\\nEven worse is if you are used to settling for the answer of \\"it\'s weird\\", you do\\nnot try to understand what is wrong. You are tempted to seek help immediately.\\nOnce you get used to that, you no longer self-learn and improve. You think you\\ndon\'t understand just because things are \\"weird\\". You learn less.\\n\\nImagine if there are network issues, rather than labelling it as a \\"weird\\ninternet problem\\", you take the time to investigate, you might figure out how\\nHTTP calls are structured, the difference between TCP and UDP, how DNS records\\npropagate, or how routing protocols work. That is how we learn.\\n\\nSo, whenever we are debugging, and when we encounter something unexpected, try\\nnot to say \\"it\'s weird\\".\\n\\n## Instead, state the facts\\n\\nThe fact is we don\'t know. We find it unexpected because we don\'t know why, and\\nthere is nothing wrong with stating that. Imagine someone coming to you to ask\\nyou a question, which way is better:\\n\\n> How do I find the log of this line in the console? Weirdly the log is not\\n> showing up.\\n\\nOr,\\n\\n> How do I find the log of this line in the console? I tried checking the\\n> browser console, but I could not find it. I don\'t know where it is logged, can\\n> you help?\\n\\nSee the difference? The first one sounds like the person is blaming some\\nweirdness that swallowed the console.log. But in fact, it is some piece of code\\nchanging the control flow causing that line not to log. Or it\'s just looking at\\nthe wrong place to find the log, it could be in the server-side console.\\n\\nTaking the unauthorized error example, instead of a filler word \\"weird\\", he\\ncould comment \\"I already put in my token, I expect the API calls to be\\nauthorized\\", and then proceed to find the source of the error.\\n\\nIt\'s mysterious and weird only because you don\'t understand how the program you\\nwrote works. State that you don\'t know what caused the unexpected behaviour is\\nbetter than labelling it as \\"weird\\".\\n\\nSooner or later you will figure out the issue. It might be some global variables\\nand side effects in functions. It might be some outdated cache. It might be race\\nconditions. Or it might be some network failure. No matter what it is, you will\\nrealize there is nothing \\"weird\\", just a lack of understanding. So, admit that\\nit\'s just you don\'t know, and you will try to understand it.\\n\\nTo get even better, state what you have tried when seeking help. Divide and\\nconquer. Check intermediate outputs. Narrow down the scope and state your\\nfindings when asking questions. \\"I tried checking the browser console\\". \\"This\\nline is logged in the console but not this\\". This shows that you are eager to\\nfigure it out and learn. You put in the effort to understand the issue and try\\nto demystify it yourself. Talk to a\\n[rubber duck](https://en.wikipedia.org/wiki/Rubber_duck_debugging) and you might\\neventually figure it out all yourself :)\\n\\nSo, avoiding saying \\"it\'s weird\\". State what you found, what you expect to see\\nand what is unexpected. It will make you sound more credible. A person who takes\\nownership."},{"id":"/2024/02/29/dual-boot-guide","metadata":{"permalink":"/blog/2024/02/29/dual-boot-guide","source":"@site/blog/2024-02-29-dual-boot-guide.md","title":"Dual Boot Windows and Ubuntu with Secure Boot and Full Disk Encryption","description":"A few months ago, I finally took the time to set up dual boot on my laptop. I","date":"2024-02-29T00:00:00.000Z","tags":[{"inline":true,"label":"Dual Boot","permalink":"/blog/tags/dual-boot"},{"inline":true,"label":"Ubuntu","permalink":"/blog/tags/ubuntu"},{"inline":true,"label":"Computers","permalink":"/blog/tags/computers"}],"readingTime":12.27,"hasTruncateMarker":true,"authors":[{"name":"Ethan Pang","url":"https://ethanppl.com/","imageURL":"https://github.com/ethanppl.png","key":"ethan","page":null}],"frontMatter":{"title":"Dual Boot Windows and Ubuntu with Secure Boot and Full Disk Encryption","tags":[{"label":"Dual Boot","permalink":"dual-boot"},{"label":"Ubuntu","permalink":"ubuntu"},{"label":"Computers","permalink":"computers"}],"toc_min_heading_level":2,"toc_max_heading_level":3,"authors":"ethan"},"unlisted":false,"prevItem":{"title":"Don\'t say it\'s a weird bug, because it makes you look stupid","permalink":"/blog/2024/06/19/weird-issue"}},"content":"A few months ago, I finally took the time to set up dual boot on my laptop. I\\nwould love to try Ubuntu as my daily driver again, while keeping the Windows OS\\njust in case. I treated this as a learning opportunity and configured dual boot\\nwith secure boot still enabled and have full disk encryption configured for both\\noperating systems.\\n\\nI wrote this blog because I could not find a single guide explains all steps for\\nsecure boot and full disk encryption sequentially, and these steps interleave\\neach other. So, I made some notes before the installation to ensure I am doing\\nthe right thing at the right time. For example, I won\'t accidentally skip a step\\nabout configuring secure boot when I am focused on following another guide about\\nfull disk encryption. This guide is a cleaned up version of the notes that I\\ncompiled for my dual boot set up.\\n\\nI organized the whole flow into 6 general steps:\\n\\n1. Preparing in Windows: set boot mode, partition disk, etc.\\n2. Configure BIOS: boot mode and other BIOS settings\\n3. Configure Ubuntu Partition: boot and data partition\\n4. Install Ubuntu: configure dual boot and mounting volumes correctly\\n5. Set up `crypttab` for full disk encryption\\n6. Reboot and fix some other issues\\n\\n\x3c!-- truncate --\x3e\\n\\nYou can do step 1 and 2 separately. From step 3 onwards, I suggest doing in 1\\nsitting, which might take an hour or more.\\n\\nWhat I have is a Lenovo ThinkPad X1 Carbon 7th Gen laptop, running Windows 11\\nhome and I would like it to dual boot into Ubuntu 22.04. And, as mentioned, with\\nsecure boot enabled in the boot process and full disk encryption for both\\noperating systems.\\n\\nNow the system has been running for a few months and things work fine. No issue\\nwith booting or decrypting the disk. It\'s a good time to document the steps and\\nshare the resources that I found helpful. Hopefully this is helpful to others\\nand maybe one day my future self.\\n\\n**Dual boot is stressful and it has risk. This guide by no means is complete.**\\nI have dual boot a few times before, so I kind of know how things look like. To\\nme, it\'s helpful to watch YouTube video of people dual booting before doing it\\nto understand what to expect. Also, check a few more guides, compare and\\nunderstand which part is common and which part is custom.\\n\\n**Make sure you have access to guides and notes on mobile or another device.**\\nYou won\'t be able to access notes in the device during dual boot. Things might\\nbreak after dual booting. Maybe the Wi-Fi card driver is not working, or\\ngraphics card config is wrong, or the pointer device is unusable. You will need\\nanother device to access your notes or search the Internet for answers.\\n\\n## Preparation in Windows\\n\\nLet\'s start!\\n\\nThe first step is to prepare for dual boot. All the steps in this stage are done\\nwithin the Windows. There is no specific order for these steps and no need to do\\nit in 1 sitting. I had my laptop running on Windows, so all the preparation are\\ndone in Windows.\\n\\n- UEFI, not BIOS\\n  - On Windows: `System Information` \u2192 `BIOS Mode` = `UEFI` instead of `Legacy`\\n  - `UEFI` is required for secure boot, GUID partition table (GPT) t\'s faster,\\n    and many other features\\n  - Read more here: https://itsfoss.com/check-uefi-or-bios/\\n- GPT, not MBR\\n  - On Windows: `Disk management` \u2192 `Create and format hard disk partitions` \u2192\\n    right-click disk \u2192 `Properties` \u2192 `Volume` \u2192 `Partition style` =\\n    `GUID Partition Table (GPT)`\\n  - Read more here: https://itsfoss.com/check-mbr-or-gpt/\\n- Use [Rufus](https://rufus.ie/en/) to create the bootable USB\\n  - Get the [Ubuntu Desktop Image](https://ubuntu.com/download/desktop)\\n  - Partition scheme: Select `GPT`\\n  - Target System: Select `UEFI`\\n- Backup BitLocker recovery key\\n  - Make sure your BitLocker recovery key is saved to your Microsoft account, or\\n    any other ways of backing it up\\n  - Read more on how to back up in\\n    [Microsoft official guide](https://support.microsoft.com/en-us/windows/back-up-your-bitlocker-recovery-key-e63607b4-77fb-4ad3-8022-d6dc428fbd0d)\\n- Partition your disk\\n  - Assuming Windows now taking up the full disk, you will need to shrink the\\n    volume available to Windows and create space for Linux\\n  - Disable BitLocker\\n    - I had to disable BitLocker to shrink the Windows volume\\n    - Follow the on-screen instructions for each to decrypt and reboot, it will\\n      take some time\\n    - Read more on\\n      [this guide about resize BitLocker partition](https://www.diskpart.com/articles/resize-bitlocker-partition-windows-10-0725.html)\\n  - Partition\\n    - I used [AOMEI Partition Assistant](https://www.diskpart.com/download.html)\\n    - Read their\\n      [How to safely partition](https://www.diskpart.com/safely-partition.html)\\n      tutorial\\n    - Other guides I found useful:\\n      [Align partition](https://www.diskpart.com/help/align-partition.html),\\n      [PreOS Mode](https://www.diskpart.com/lib/PreOS-mode.html)\\n    - If you want to use the Disk Management tool from Windows but failed,\\n      [this post](https://answers.microsoft.com/en-us/windows/forum/all/windows-disk-management-unable-to-shrink-c-drive/217c3521-b254-4662-bac9-bc90dc633fab)\\n      might be helpful\\n  - Move `WinRe` partition after the Windows partition\\n    - This is the recovery partition for Windows to support failover\\n    - It is recommended to keep this as a separate partition and put it right\\n      after the Windows partition\\n    - Read more on\\n      [this post](https://learn.microsoft.com/en-us/answers/questions/1354739/the-recovery-partition-is-typically-created-at-the)\\n    - So what I had is [Windows | WinRe | Unused space (for Ubuntu later)]\\n\\n## Configure BIOS in the BIOS Menu\\n\\nJust to make sure a few things are set in the BIOS menu. Knowing how to get into\\nthe BIOS menu is also helpful in case of bad things happened.\\n\\nReboot the computer and enter the BIOS menu before the OS load. Search online\\nhow to do it for your computer. It\'s usually F2 or F12. For me is pressing Enter\\nwhen it says something like \\"Press Enter to interrupt\\".\\n\\nThings to check:\\n\\n- Make sure the UEFI BIOS is up-to-date\\n- SATA mode is `AHCI`, as Ubuntu doesn\'t support other operations\\n- Secure boot is enabled and CSM is disabled\\n  - It is required to install Ubuntu with secure boot enabled for secure boot to\\n    work with Ubuntu\\n  - CSM is to support non-UEFI OS. It should already be disabled with secure\\n    boot enabled\\n- Boot mode is UEFI only\\n- TPM security has to be enabled for BitLocker in Windows\\n- You can check the Boot order in the BIOS menu as well\\n\\n## Configure Ubuntu Partition\\n\\nThe important bits start here! From now on, it\'s better to do all remaining\\nsteps in one go.\\n\\nThis stage is to boot into Ubuntu with the live USB and configure the Ubuntu\\npartition that is encrypted.\\n\\n1. Boot the USB stick and select `Try without installing` when prompted\\n2. You should see the default Ubuntu desktop, open a terminal\\n3. In the terminal, change to root with\\n   ```bash\\n   sudo su\\n   ```\\n4. Check the partition table again\\n   1. Check with `sgdisk`\\n      ```bash\\n      sgdisk --print /dev/nvme0n1\\n      ```\\n   2. If your disk is not `/dev/nvme0n1`, then you will have to replace all the\\n      following commands to your disk name, e.g. `/dev/sda`\\n   3. Look for the disk name (e.g. `/dev/sda` or `/dev/nvme0n1`) not the\\n      partition name (e.g. `/dev/sda1` or `/dev/nvme0n1p1`)\\n5. Create 2 partitions in the empty space in your disk, one for boot and the\\n   rest for root\\n   1. New 1800M partition for boot\\n      ```bash\\n      sgdisk --new=5:0:+1800M /dev/nvme0n1\\n      ```\\n   2. New partition using the rest for root\\n      ```bash\\n      sgdisk --new=6:0:0 /dev/nvme0n1\\n      ```\\n   3. Name the partitions\\n      ```bash\\n      sgdisk --change-name=5:/boot --change-name=6:rootfs /dev/nvme0n1\\n      ```\\n   4. Choose 8300 as the type code for the file system (Linux filesystem)\\n      ```bash\\n      sgdisk --typecode=5:8300 --typecode=6:8300 /dev/nvme0n1\\n      ```\\n      (you can find all typecode with `sgdisk -L`)\\n   5. Make EXT4 file system (notice that here is the partition name)\\n      ```bash\\n      mkfs.ext4 -L boot /dev/nvme0n1p5\\n      ```\\n6. Encrypt the Linux data partition with LUKS\\n\\n   - In the following codeblock, I am showing the output as well\\n   - Lines after `#` are what needed to be inputted to the terminal\\n   - The passphrase you chose at this step is what you needed to decrypt the\\n     disk when booting\\n\\n   ```bash\\n   # cryptsetup luksFormat --type=luks2 /dev/nvme0n1p6\\n   WARNING!\\n   ========\\n   This will overwrite data on /dev/nvme0n1p6 irrevocably.\\n\\n   Are you sure? (Type uppercase yes): YES\\n   Enter passphrase for /dev/nvme0n1p6:\\n   Verify passphrase:\\n\\n   # cryptsetup open /dev/nvme0n1p6 nvme0n1p6_crypt\\n   Enter passphrase for /dev/nvme0n1p6:\\n\\n   # ls /dev/mapper/\\n   control nvme0n1p6_crypt\\n   ```\\n\\n7. Set up logical volume manager (LVM), with root, swap and home partition\\n   ```bash\\n   # pvcreate /dev/mapper/nvme0n1p6_crypt\\n   Physical volume \\"/dev/mapper/nvme0n1p6_crypt\\" successfully created.\\n   # vgcreate ubuntu-vg /dev/mapper/nvme0n1p6_crypt\\n   Volume group \\"ubuntu-vg\\" successfully created\\n   # lvcreate -L 64G -n root ubuntu-vg\\n   Logical volume \\"root\\" created.\\n   # lvcreate -L 16G -n swap ubuntu-vg\\n   Logical volume \\"swap\\" created.\\n   # lvcreate -l 100%FREE -n home ubuntu-vg\\n   Logical volume \\"home\\" created.\\n   ```\\n\\nNow all the Ubuntu partitions are prepared. Without exiting the live\\nenvironment, use the GUI to continue the installation.\\n\\n## Install Ubuntu\\n\\nWe will install Ubuntu on the encrypted disk and configure things to make sure\\nsecure boot also works.\\n\\n1. Run the graphical installer\\n2. Connect to your Wi-Fi network\\n3. On the software step, for \\"Other options\\" (This step is important for secure\\n   boot to work)\\n   1. Check the \\"Download updates\\" option\\n   2. Check the \\"Install third-party software for graphics and Wi-Fi hardware\\"\\n   3. Check the \\"Configure Secure Boot\\" option and enter a password, remember\\n      this password. Useful for the MOK management step explained below.\\n   4. Save and continue\\n4. When asked what to do with the disk, pick \\"Something else\\", or the option\\n   that allows you to manually assign disk partition\\n   1. Use the ~1800MB partition as `ext4` with mount point as `/boot`\\n   2. Use the `/dev/mapper/ubuntu-vg-root` as `ext4` FS and mount it to `/`\\n   3. Use the `/dev/mapper/ubuntu-vg-home` as `ext4` FS and mount it to `/home`\\n   4. Use the `/dev/mapper/ubuntu-vg-swap` as `swap`\\n   5. Do the same as above if you have more or less partitions\\n   6. The bootloader device should be `/dev/nvme0n1`\\n5. Proceed with the installation\\n6. When finished, select `Continue Testing`, and it should bring you back to the\\n   Ubuntu Desktop environment\\n\\nDo not leave the live environment just yet.\\n\\n## Set up `crypttab`\\n\\n`crypttab` is used to decrypt the disk on boot.\\n\\n1. Open the terminal and find the UUID of the partition with LUKS\\n   ```bash\\n   sudo blkid /dev/nvme0n1p6\\n   ```\\n   Example output:\\n   ```\\n   /dev/nvme0n1p6: UUID=\\"abcdefgh-1234-5678-9012-abcdefghijklm\\" TYPE=\\"crypto_LUKS\\"\\n   ```\\n   I suggest writing the UUID down somewhere\\n2. Mount the drives and chroot into the mount:\\n\\n   ```bash\\n   mount /dev/mapper/ubuntu-vg-root /target\\n   mount /dev/nvme0n1p5 /target/boot\\n   for n in proc sys dev etc/resolv.conf; do mount --rbind /$n /target/$n; done\\n   chroot /target\\n\\n   mount -a\\n   ```\\n\\n3. Configure `/etc/crypttab`:\\n\\n   ```\\n   # <target name> <source device> <key file> <options>\\n   # options used:\\n   #     luks    - specifies that this is a LUKS encrypted device\\n   #     tries=0 - allows to re-enter password unlimited number of times\\n   #     discard - allows SSD TRIM command, WARNING: potential security risk (more: \\"man crypttab\\")\\n   #     loud    - display all warnings\\n   nvme0n1p6_crypt UUID=abcdefgh-1234-5678-9012-abcdefghijklm none luks,discard\\n   ```\\n\\n4. Apply the changes (still inside chroot)\\n   ```bash\\n   update-initramfs -k all -c\\n   ```\\n\\n## Reboot and some remaining issues\\n\\n### Blue screen MOK management\\n\\n1. When reboot, because of the secure boot, you will see a blue screen and ask\\n   to perform MOK management\\n2. Choose Enroll MOK, continue, yes\\n3. Input the password that you inputted on the step for software install during\\n   the installation for third party drivers\\n   - It won\'t show what you typed, trust that it\'s there\\n   - This is only a one time thing so no worries\\n   - Once successful you don\'t need the password anymore\\n\\n### Windows BitLocker Issue\\n\\nYou might need to input the BitLocker recovery key when booting into Windows.\\nFind your recovery key in where ever you saved (e.g. Microsoft account) and\\ninput it. This is also one time thing, so no worries.\\n\\nIf you have disabled BitLocker before to partition the disk, you will need to\\nre-enable it and encrypt the Windows partition again.\\n\\nTo encrypt again, you need to make sure you meet the pre-requisites to enable\\nBitLocker:\\n\\n- Check that the partition table is GPT\\n- BIOS is set to UEFI\\n- Secure boot is enabled\\n\\nGo to `System information` \u2192 scroll down and see device encryption support needs\\nto be `meets prerequisites`. If not, check the above again and maybe reboot and\\nsee.\\n\\nOnce the prerequisites are met, go to Settings \u2192 privacy & security \u2192 device\\nencryption and enable BitLocker.\\n\\nTo check the progress:\\n\\n- Open admin command prompt and input `manage-bde -status C:`\\n- If the status stuck, not updating, try `manage-bde -pause C:` and then\\n  `manage-bde -resume C:`\\n\\nWith BitLocker re-enabled, this means both Ubuntu and Windows have full disk\\nencryption and secure boot enabled!\\n\\n### Wrong timezone after dual boot\\n\\nYou might notice one of the OS show the wrong time before resyncing their time.\\nThis is because they store time into the computer hardware clock differently.\\nLinux assumes that the time on the hardware clock is stored in UTC and Windows\\nassumes it is local time. One solution is to ask Linux to store the hardware\\nclock as local time:\\n\\n```bash\\ntimedatectl set-local-rtc 1\\n```\\n\\n[Read more in this guide from It\'s Foss](https://itsfoss.com/wrong-time-dual-boot/)\\n\\n## References\\n\\n### About full disk encryption:\\n\\n- [How to Dual-Boot Ubuntu 20.04 (or 22.04) and Windows 10 (or 11) with Encryption | Mike Kasberg](https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html) -\\n  recommend reading\\n- [Dual boot with encryption nodes | GitHub Gist from @luispabon](https://gist.github.com/luispabon/db2c9e5f6cc73bb37812a19a40e137bc)\\n\\n### About secure boot:\\n\\n- [Can I enable secure boot again? | Reddit](https://www.reddit.com/r/linux4noobs/comments/osotp3/ubuntu_dual_boot_with_windows_10_can_i_enable/) -\\n  Ans: no\\n- [A Clean Install of Linux Ubuntu 20.04 (Lenovo UEFI BIOS with Secure Boot and MOK) | YouTube](https://youtu.be/GqJBniwj1Mg) -\\n  worth watching parts about the secure boot and MOK step\\n- [It is possible to dual boot Linux and Windows 10 with secure boot enabled? | Ask Ubuntu](https://askubuntu.com/questions/880240/it-is-possible-to-dual-boot-linux-and-windows-10-with-secure-boot-enabled) -\\n  Ans: yes\\n\\n### About partition and BitLocker:\\n\\n- [Windows Disk Management unable to shrink C: drive volume](https://answers.microsoft.com/en-us/windows/forum/all/windows-disk-management-unable-to-shrink-c-drive/217c3521-b254-4662-bac9-bc90dc633fab)\\n- [How can I resize BitLocker partition in Windows 10/11](https://www.diskpart.com/articles/resize-bitlocker-partition-windows-10-0725.html)\\n- [Dual Booting Ubuntu with Windows 10 Pro with BitLocker Encryption](https://itsfoss.com/dual-boot-ubuntu-windows-bitlocker/)\\n\\nThat\'s it and I hope you can set up dual boot without issues!"}]}}')}}]);