"use strict";(self.webpackChunkmy_wiki=self.webpackChunkmy_wiki||[]).push([[3208],{7600:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>d,frontMatter:()=>r,metadata:()=>a,toc:()=>c});var t=i(5893),s=i(1151);const r={},l="Large Language Model",a={id:"computers/ai/llm",title:"Large Language Model",description:"Resources",source:"@site/docs/computers/ai/llm.md",sourceDirName:"computers/ai",slug:"/computers/ai/llm",permalink:"/wiki/computers/ai/llm",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Artificial Intelligence",permalink:"/wiki/computers/ai/"},next:{title:"Prompting",permalink:"/wiki/computers/ai/prompting"}},o={},c=[{value:"Resources",id:"resources",level:2},{value:"Links",id:"links",level:2}];function h(e){const n={a:"a",h1:"h1",h2:"h2",li:"li",ul:"ul",...(0,s.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"large-language-model",children:"Large Language Model"}),"\n",(0,t.jsx)(n.h2,{id:"resources",children:"Resources"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://magazine.sebastianraschka.com/p/understanding-large-language-models",children:"Understanding large language models"}),"\n(",(0,t.jsx)(n.a,{href:"https://news.ycombinator.com/item?id=35589756",children:"HN"}),")","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Top 10-ish papers to understand the design, constraints and evolution of\nLLMs"}),"\n",(0,t.jsx)(n.li,{children:"Development of LLMs: Attention weighted encodings, transformer, BERT, GPT,\nBART"}),"\n",(0,t.jsx)(n.li,{children:"Improving the efficiency of LLMs: FlashAttention, Cramming, finetuning\nmethods, Chinchilla model, InstructGPT, and more on reinforcement learning\nwith human feedback (RLHF)"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://willthompson.name/what-we-know-about-llms-primer",children:"What we know about LLMs (Primer) | Will Thompson"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"A simple explainer of what is considered an LLM, what we knew about LLMs and\nwhat are the ongoing research"}),"\n",(0,t.jsx)(n.li,{children:"Includes a lot of links to other resources. A few concepts introduced\ninclude LLMs' capability to generalize knowledge, power law in LLMs'\nperformance, reinforcement learning via human feedback (RLHF), etc."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"links",children:"Links"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://www.atmosera.com/ai/understanding-chatgpt/",children:"Understanding ChatGPT | Atmosera"}),"\n(",(0,t.jsx)(n.a,{href:"https://news.ycombinator.com/item?id=35312468",children:"HN"}),")","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Understand how things went from RRN to LSTM to Transformer, to BERT, to GPT"}),"\n",(0,t.jsx)(n.li,{children:"Contains a brief explanation of each advancement and links to all the\nimportant papers"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/mlc-ai/web-llm",children:"Web LLM | GitHub @mlc-ai"})," \u2014 Running LLM\ndirectly in the browser"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://blog.replit.com/llm-training",children:"How Replit train their own Large Language Models"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Data processing (Databricks) \u2192 Custom tokenization \u2192 Model training\n(MosaicML) \u2192 Evaluation (HumanEval framework)"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://www.honeycomb.io/blog/hard-stuff-nobody-talks-about-llm",children:"All the Hard Stuff Nobody Talks About when Building Products with LLMs | Honeycomb.io"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"It's hard to build a real product backed by an LLM"}),"\n",(0,t.jsx)(n.li,{children:"Limited context windows, LLMs are slow and chaining is impractical, prompt\nengineering is weird, prompt injection, etc"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://simonwillison.net/2023/Jun/8/gpt-tokenizers/",children:"Understanding GPT tokenizers | Simon Willison"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Optimizations by including leading space in the token"}),"\n",(0,t.jsx)(n.li,{children:"The tokenization is biased towards English words"}),"\n",(0,t.jsx)(n.li,{children:"Glitch tokens: words that have no meaning but got tokenized, and get near 0\nweight after training lead to weird glitch"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://cameronrwolfe.substack.com/p/the-history-of-open-source-llms-better",children:"The history of open-source LLMs | Deep (Learning) Focus"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Nice graphs and tables visualizing the performances of different LLMs"}),"\n",(0,t.jsx)(n.li,{children:"Explains the evolution from lower-quality LLMs (BLOOM and OPT) to recent\npowerful models (LLaMA and MPT)"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://eugeneyan.com/writing/llm-patterns/",children:"Patterns for Building LLM-based Systems & Products"}),"\n(",(0,t.jsx)(n.a,{href:"https://news.ycombinator.com/item?id=36965993",children:"HN"}),")","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Will be a long read. Contains patterns for the following seven topics:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Evaluations: to measure the performance of the models"}),"\n",(0,t.jsx)(n.li,{children:"Retrieval-Augmented Generation (RAG): to provide richer context to the\nmodel"}),"\n",(0,t.jsx)(n.li,{children:"Fine-tuning: to get better at specific tasks, usually a domain-specific\ndataset"}),"\n",(0,t.jsx)(n.li,{children:"Caching: to reduce latency and cost for semantically similar requests"}),"\n",(0,t.jsx)(n.li,{children:"Guardrails: to ensure output quality (syntactically and factually correct,\nfree from harmful content)"}),"\n",(0,t.jsx)(n.li,{children:"Defensive UX: guide user behaviour, avert possible misuse & handle errors\ngracefully"}),"\n",(0,t.jsx)(n.li,{children:"Collect user feedback: incorporate user feedback into the UX design to\nbuild a data flywheel"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://huyenchip.com/2023/08/16/llm-research-open-challenges.html",children:"10 open challenges in LLM research | Chip Huyen"}),"\n(",(0,t.jsx)(n.a,{href:"https://news.ycombinator.com/item?id=37155080",children:"HN"}),")","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Reduce & measure hallucinations, optimize context construction, multimodal\ninputs, faster & cheaper, new architecture, GPU alternatives, agents acting\non behalf of LLM, human preference, chat interface, non-English language"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://benchmarks.llmonitor.com/",children:"Asking 60+ LLMs a set of 20 questions"}),"\n(",(0,t.jsx)(n.a,{href:"https://news.ycombinator.com/item?id=37445401",children:"HN"}),")","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Benchmarking LLMs with some reflexion, knowledge, code, instructions and\ncreativity questions"}),"\n",(0,t.jsx)(n.li,{children:"More \"realistic\" benchmarks then those exams because it's likely it's\noutside the training set"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://ig.ft.com/generative-ai/",children:"How transformers work"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Nice graphics explaining concepts like embeddings, self-attention mechanism,\nbeam search and hallucination"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://www.anthropic.com/index/decomposing-language-models-into-understandable-components",children:"Decomposing Language Models Into Understandable Components"}),"\n(",(0,t.jsx)(n.a,{href:"https://news.ycombinator.com/item?id=37806861",children:"HN"}),")","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:'A single neuron does not have consistent meaning, but a group of neurons\ndoes, called "features"'}),"\n",(0,t.jsx)(n.li,{children:"Artificially activating features can steer the output of models, improving\nsecurity and our understanding of LLMs"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/spdustin/ChatGPT-AutoExpert/blob/main/System%20Prompts.md",children:"ChatGPT system prompts"}),"\n(",(0,t.jsx)(n.a,{href:"https://news.ycombinator.com/item?id=37879077",children:"HN"}),")","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://old.reddit.com/r/OpenAI/comments/176mxj8/chatgpt_with_vision_system_prompt/k4r5lyh/",children:"How it's done by OP"})}),"\n"]}),"\n"]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}},1151:(e,n,i)=>{i.d(n,{Z:()=>a,a:()=>l});var t=i(7294);const s={},r=t.createContext(s);function l(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);